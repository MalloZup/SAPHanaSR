#!/bin/bash
#
# SAPHana
#
# Description:	Manages a single SAP HANA Instance or two of them in System 
#               Replication Planned: do also manage scale-up scenarios
#               currently the SAPHana is dependent of the analysis of 
#               SAPHanaTopology
#
##############################################################################
#
# SAPHana is a fork of SAPInstance to cover special actions needed for running HANA in a SR mode
# Thanks to Alexander Krauth for providing SAPInstance and SAPDatabase
#
# SAPHana:
# Author:       Fabian Herschel, November 2013
# Support:      linux@sap.com
# License:      GNU General Public License (GPL)
# Copyright:    (c) 2013 SUSE Linux Products GmbH
#
# An example usage: 
#      See usage() function below for more details...
#
# OCF instance parameters:
#	OCF_RESKEY_SID
#	OCF_RESKEY_InstanceNr       
#	OCF_RESKEY_DIR_EXECUTABLE   (optional, well known directories will be searched by default)
#	OCF_RESKEY_DIR_PROFILE      (optional, well known directories will be searched by default)
#	OCF_RESKEY_INSTANCE_PROFILE (optional, well known directories will be searched by default)
#   OCF_RESKEY_PREFER_SITE_TAKEOVER (optional, default is no)
#   OCF_RESKEY_DUPLICATE_PRIMARY_TIMEOUT (optional, time difference needed between two last-primary-tiemstampe (lpt))
#   OCF_RESKEY_SAPHanaFilter    (optional)
#
#   TODO: PRIO1: See TODOs in this script
#   TODO: PRIO1: Secondary mit SFAIL sollte eventuell auf lpa=30 gesetzt werden?
#   TODO: PRIO3: Absolutely minimize setting of attributes (each set should check first)
#   TODO: PRIO2: Primary alone in cluster (other standby - does it set its own attribute to SFAIL?) should set it to PRIM
#   DONE: ASK: What to do on landscapeHostConfiguration return code 2 (=WARN)? ANSW: ->> keep!!!
#   DONE: ASK: Do we need to support virtual hostnames for SAPHana like we have for SAPInstance?  ->> ANSW: YES!!!
#   TODO: PRIO3: How to "migrate" a primary? Simply promote the secondary does not work as the running primary will not be demoted to a secondary
#   TODO: PRIO1: NUR Return-Code 1 von landscapeHostConfiguration.py führt zur Übernahme!! ReturnCode 0 nicht!!
#   TODO: PRIO3: Virtual Hostname mit saphostctrl -function ListInstances -> search SID/Ino -> Virtual Host
#   TODO: PRIO3: avoid su-commands
#   TODO: PRIO5: For SCALE-OUT only:
#         How to prevent a parallel takeover to remote site AND local switchover of Row-Space in post-productive swarm, if PREFER_SITE_TAKEOVER
#         Was zeigt landscapeHostConfiguration beim localen SAPHanaHA Umbau an?
#         Kann man der localen SAPHana site sagen "halt die füsse still"? Oder ist es zunächst einmal "egal" ob wir parallel sr_takeover machen
#         können 
#   DONE: lpa-lpt should have a spbilizing-gab of 2hours - so per default the lpts during start must differ at least 2h or we say stalemate
#   DONE: the lpa-lpt-gab should be configurable (with default 2h -> 7200 sec) for testing purposes -> DUPLICATE_PRIMARY_TIMEOUT
#   TODO: PRIO2: Handle crash of BOTH hana deamons
#   TODO: PRIO1: COME OUT OF WATING SITS
#   TODO: PRIO2: ASK:  DESCRIBE FOR MATTHIAS MAENNICH WHICH HOOKS WOULD BE HELPFUL
#   TODO: PRIO3: SCRIPT FOR UPDATE PROCEDURE (ROLLING UPDATE)
#   TODO: PRIO5: For SCALE-OUT only: Need scoring table for primary/secondary master/slave/xxx
#
#         I) with prefer-site-takeover (without optimized local takeover)
#                 primary/PRIM     secondary/SOK  secondary/SFAIL   other
#         master     150           100                               -inf
#         slave       60            10            -inf               -inf
#         ? (down)     ?             0                               -inf
#         UKNOWN    -inf          -inf            -inf               -inf
#
#         ( 100 points for master, +50 points for primary OR +10 points for slave, BUT -INFINITY, if SFAIL or secondary/down )
#
#         II) with noprefer-site-takeover
#                 primary/PRIM     secondary/SOK  secondary/SFAIL   other
#         master     150            50             -inf             -inf
#         slave      110            10             -inf             -inf
#         ? (down)     ?             0             -inf             -inf
#         UKNOWN    -inf           -inf            -inf             -inf
#        
#   USED CLUSTER CLI COMMANDS:  crm_master, crm_attribute (get/set), crm_node
#   USED SAP HANA CLI COMMANDS: hdbsql, hdbnsutil, landscapeHostConfiguration.py, sapcontrol
#
#######################################################################
#
# Initialization:
timeB=$(date '+%s')

: ${OCF_FUNCTIONS_DIR=${OCF_ROOT}/lib/heartbeat}
. ${OCF_FUNCTIONS_DIR}/ocf-shellfuncs

#
#######################################################################
#

HANA_STATE_PRIMARY=0
HANA_STATE_SECONDARY=1
HANA_STATE_DEFECT=2

SH=/bin/sh

#
# function: super_ocf_log - wrapper function for ocf log in order catch usual logging into super log
# params:   LOG_MESSAGE
# globals:  SAPHanaFilter
function super_ocf_log() {
    local level="$1"
    local message="$2"
    local skip=1
    local mtype=""
    local search=0
    local shf="${SAPHanaFilter:-all}"
    # message levels: (dbg)|info|warn|err|error
    # message types:  (fhACT|fhRA|fhFLOW|fhDBG|fhLPA|fhDEC|fhDBG2...
    case "$level" in
        dbg | warn | err | error ) skip=0
        ;;
        info )
        case "$shf" in
            all) skip=0
            ;;          
            none )
                skip=1
                ;;
            * ) mtype=${message%% *}
                mtype=${mtype%:}
                mtype=${mtype#fh}
                echo "$shf"|  grep -iq ${mtype}; search=$?
                if [ $search -eq 0 ]; then
                     skip=0  
                else
                    skip=1
                fi
            ;;
        esac
        ;;    
    esac
    if [ $skip -eq 0 ]; then
        ocf_log "$level" "$message"
    fi
}

#
# function: saphana_usage - short usage info
# params:   -
# globals:  $0(r)
#
function saphana_usage() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
    methods=$(saphana_methods)
    methods=$(echo $methods | tr ' ' '|')
  cat <<-!
	usage: $0 ($methods)

    $0 manages a SAP HANA Instance as an HA resource.

    The 'start'        operation starts the HANA instance or bring the "clone instance" to a WAITING status
    The 'stop'         operation stops the HANA instance
    The 'status'       operation reports whether the HANA instance is running
    The 'monitor'      operation reports whether the HANA instance seems to be working in master/slave it also needs to check the system replication status
    The 'promote'      operation either runs a takeover for a secondary or a just-nothing for a primary
    The 'demote'       operation neary does nothing and just mark the instance as demoted
    The 'notify'       operation always returns SUCCESS
    The 'validate-all' operation reports whether the parameters are valid
    The 'methods'      operation reports on the methods $0 supports

	!
	return $rc
}

#
# function: saphana_meta_data - print resource agent meta-data for cluster
# params:   -
# globals:  -
#
function saphana_meta_data() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
	cat <<END
<?xml version="1.0"?>
<!DOCTYPE resource-agent SYSTEM "ra-api-1.dtd">
<resource-agent name="SAPHana">
<version>0.117.2014.04.02.6</version>

<shortdesc lang="en">Manages two SAP HANA instances in sytem replication (SR).</shortdesc>
<longdesc lang="en">
TODO: PRIO3 TBD

1. Interface to start/stop a HANA instance/system: sapcontrol/sapstartsrv
sapstartsrv knows 4 status colours:
- GREEN   = everything is fine
- YELLOW  = something is wrong, but the service is still working
- RED     = the service does not work
- GRAY    = the service has not been started
The SAPHana resource agent will interpret GREEN and YELLOW as OK. That means that minor problems will not be reported to the Heartbeat cluster. This prevents the cluster from doing an unwanted failover.
The statuses RED and GRAY are reported as NOT_RUNNING to the cluster. Depending on the status the cluster expects from the resource, it will do a restart, failover or just nothing.

2. Interface to monitor a HANA system: landscapeHostConfiguration.py 
landscapeHostConfiguration.py has some detailed output about HANA system status
and node roles. For our monitor the overall status is relevant. This overall 
status is reported by the returncode of the script:
0: Internal Fatal
1: ERROR
2: WARNING
3: INFO (maybe a switch of the resource running)
4: OK
The SAPHana resource agent will interpret returncodes 0+1 as NOT-RUNNING (or 1 failure) and returncodes 2+3+4 as RUNNING.

3. Interface is hdbnsutil
TODO PRIO3: TBD

4. Interface is SQL query into HANA (system replication table)
TODO PRIO3: TBD

</longdesc>
<parameters>
    <parameter name="SID" unique="0" required="1">
        <longdesc lang="en">TBD</longdesc>
        <shortdesc lang="en">TBD</shortdesc>
        <content type="string" default="" />
    </parameter>
    <parameter name="InstanceNumber" unique="0" required="1">
        <longdesc lang="en">TBD</longdesc>
        <shortdesc lang="en">TBD</shortdesc>
        <content type="string" default="" />
    </parameter>
    <parameter name="PREFER_SITE_TAKEOVER" unique="0" required="0">
        <longdesc lang="en">Should cluster/RA prefer to switchover to slave instance instead of restarting master locally? Default=0 
        0: Do restart locally
        1: Do takever to remote site
        </longdesc>
        <shortdesc lang="en">Local or site recover preferred?</shortdesc>
        <content type="string" default="0" />
    </parameter>
    <parameter name="DUPLICATE_PRIMARY_TIMEOUT" unique="0" required="0">
        <shortdesc lang="en">Time difference needed between to primary time stamps, if a dual-primary situation occurs</shortdesc>
        <longdesc lang="en">TBD
        TODO: PRIO3: DUPLICATE_PRIMARY_TIMEOUT long description
        </longdesc>
        <content type="string" default="7200" />
    </parameter>
    <parameter name="DIR_EXECUTABLE" unique="0" required="0">
        <longdesc lang="en">The full qualified path where to find sapstartsrv and sapcontrol. Specify this parameter, if you have changed the SAP kernel directory location after the default SAP installation.</longdesc>
        <shortdesc lang="en">Path of sapstartsrv and sapcontrol</shortdesc>
        <content type="string" default="" />
    </parameter>
    <parameter name="DIR_PROFILE" unique="0" required="0">
        <longdesc lang="en">The full qualified path where to find the SAP START profile. Specify this parameter, if you have changed the SAP profile directory location after the default SAP installation.</longdesc>
        <shortdesc lang="en">Path of start profile</shortdesc>
        <content type="string" default="" />
    </parameter>
    <parameter name="INSTANCE_PROFILE" unique="1" required="0">
        <longdesc lang="en">The name of the SAP START profile. Specify this parameter, if you have changed the name of the SAP START profile after the default SAP installation. As SAP release 7.10 does not have a START profile anymore, you need to specify the Instance Profile than.</longdesc>
        <shortdesc lang="en">HANA instance profile name</shortdesc>
        <content type="string" default="" />
    </parameter>
    <parameter name="SAPHanaFilter" unique="0" required="0">
        <shortdesc lang="en">Define SAPHana messages to be printed</shortdesc>
        <longdesc lang="en">Define SAPHana messages to be printed. Currently only partially implemented.
 Values: all, none, 
 TODO: PRIO3: describe which combinations are supported
 Planned: Allowed values are all, none (and combinations of): dbg, dec, lpa, func
        </longdesc>
        <content type="string" default="sync" />
    </parameter>
</parameters>

<actions>
    <action name="start" timeout="180" />
    <action name="stop" timeout="240" />
    <action name="status" timeout="60" />
    <action name="monitor" depth="0" timeout="60" interval="120" />
    <action name="monitor" depth="0" timeout="60" interval="121" role="Slave" />
    <action name="monitor" depth="0" timeout="60" interval="119" role="Master" />
    <action name="promote" timeout="320" />
    <action name="demote" timeout="320" />
    <action name="validate-all" timeout="5" />
    <action name="meta-data" timeout="5" />
    <action name="methods" timeout="5" />
</actions>
</resource-agent>
END
return $rc
}


#
# function: saphana_methods - report supported cluster methods
# params:   -
# globals:  -
# methods: What methods/operations do we support?
#
function saphana_methods() {
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local rc=0
  cat <<-!
    start
    stop
    status
    monitor
    promote
    demote
    notify
    validate-all
    methods
    meta-data
    usage
	!
	return $rc
}

#
# function: dequote - filter: remove quotes (") from stdin
# params:   -
# globals:  -
#
function dequote()
{
    local rc=$?
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    tr -d '"'
    return $rc
}

#
# function: is_clone - report, if resource is configured as a clone (also master/slave)
# params:   -
# globals:  OCF_*(r)
# descript: is_clone : find out if we are configured to run in a Master/Slave configuration
#   rc: 0: it is a clone
#       1: it is not a clone
#   Special EXIT of RA, if clone is missconfigured
#
function is_clone() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
    #
    # is a clone config?
    #
    if [ -n "$OCF_RESKEY_CRM_meta_clone_max" ] \
       && [ "$OCF_RESKEY_CRM_meta_clone_max" -gt 0 ]; then
       #
       # yes it is a clone config - check, if its configured well
       #
        if [ "$OCF_RESKEY_CRM_meta_clone_node_max" -ne 1 ] || \
            [ "$OCF_RESKEY_CRM_meta_master_node_max" -ne 1 ] || \
            [ "$OCF_RESKEY_CRM_meta_master_max" -ne 1 ]; then
                super_ocf_log err "fhACT Clone options misconfigured. (expect: clone_node_max=1,master_node_max=1,master_max=1)"
                exit $OCF_ERR_CONFIGURED
        fi
        rc=0;
    else
        rc=1;
    fi
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# function: get_hana_attribute 
# params:   NODE ATTR [STORE]
# globals:  -
#
function get_hana_attribute()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
    local attr_node=$1
    local attr_name=$2
    local attr_store=${3:-reboot} # DONE: PRIO5 get this (optional) from parameter
    crm_attribute -N ${attr_node} -G -n "$attr_name" -l $attr_store -q; rc=$?
    super_ocf_log info "fhFLOW function: $FUNCNAME rc=$rc"
    return $rc
}

#
# function: set_hana_attribute - set the multi-state status of a node
# params:   NODE VALUE ATTR [STORE]
# globals:  -
#
function set_hana_attribute()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local attr_node=$1
    local attr_value=$2
    local attr_name=$3
    local attr_store=${4:-reboot} # DONE: PRIO5 get this (optional) from parameter
    local rc=1
    local attr_old=""
    attr_old=$(get_hana_attribute $attr_node $attr_name $attr_store); get_rc=$?
    if [ "$attr_old" != "$attr_value" ]; then
        super_ocf_log info "fhDBG SET attribute $attr_name for node ${attr_node} to ${attr_value} former ($attr_old) get_rc=$get_rc "
        crm_attribute -N $attr_node -v $attr_value -n "$attr_name" -l $attr_store; rc=$?
    else
        super_ocf_log info "fhDBG LET attribute $attr_name for node ${attr_node} still be ${attr_value}"
        rc=0
    fi
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# function: assert - quickly go out of here with minimal error/return code handling and log
# params:   MESSAGE
# globals:  OCF_*(r)
# assert : essential things are missing, but in the natur of a SAP installation - which can be very different
#                from customer to customer - we cannot handle this always as an error
#                This would be the case, if the software is installed on shared disks and not visible
#                to all cluster nodes at all times.
#
function assert() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local err_msg=$1 local default_rc=$OCF_NOT_RUNNING

    # DONE: Check, if we need to destinguish between probe and others
    if ocf_is_probe; then
        default_exit=$OCF_NOT_RUNNING
    else
        default_exit=$OCF_ERR_CONFIGURED
    fi

    if [ "$ACTION" = "stop" ]; then
        cleanup_instance
        exit $OCF_SUCCESS
    fi

    super_ocf_log err "fhACT $err_msg"
    exit $default_exit
}

#
# function: set_crm_master - set the crm master score of the local node
# params:   SCORE
# globals:  HA_SBIN_DIR(r), OCF_RESOURCE_INSTANCE(r)
#
function set_crm_master()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
    local score=0
    if [ -n "$1" ]; then
        score=$1
    fi 
    # DONE: PRIO2: Only adjust master if value is really different (try to check that)
    oldscore=$(${HA_SBIN_DIR}/crm_master -G -q -l reboot)
    if [ "$oldscore" != "$score" ]; then
       super_ocf_log info "fhDBG: SET crm master: $score (old: $oldscore)"
       ${HA_SBIN_DIR}/crm_master -v $score -l reboot; rc=$?
    else
       super_ocf_log info "fhDBG: LET crm master: $score"
       rc=0
    fi
    #logger -t fhLOG "crm_master with: $OCF_RESOURCE_INSTANCE -v $score -l reboot"
    return $rc
}

#
# function: scoring_crm_master - score instance due to role ans sync match (table SCORING_TABLE_PREFERRED_SITE_TAKEOVER)
# params:   NODE_ROLES NODE_SYNC_STATUS
# globals:  SCORING_TABLE_PREFERRED_SITE_TAKEOVER[@], 
#
scoring_crm_master()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local roles="$1"
    local sync="$2"
    local skip=0
    local myScore=-1
    for scan in "${SCORING_TABLE_PREFERRED_SITE_TAKEOVER[@]}"; do
        if [ $skip -eq 0 ]; then
            read rolePatt syncPatt score <<< $scan
            if grep "$rolePatt" <<< "$roles"; then
               if grep "$syncPatt" <<< "$sync"; then
                  skip=1
                  myScore=$score 
               fi
            fi
        fi
    done
    super_ocf_log info "fhDBG: scoring_crm_master adjust score $myScore"
    set_crm_master $myScore
}

#
# function: get_crm_master - get the crm master score of the local node
# params:   -
# globals:  HA_SBIN_DIR(r)
#
function get_crm_master()
{
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local rc=0
   ${HA_SBIN_DIR}/crm_master -G -q -l reboot; rc=$?
   return $rc
}

#
# function: saphana_init - initialize variables for the resource agent
# params:   InstanceName
# globals:  OCF_*(r), SID(w), sid(rw), sidadm(w), InstanceName(w), InstanceNr(w), SAPVIRHOST(w), PreferSiteTakeover(w), 
# globals:  meta_notify_master_uname(w), sr_name(w), remoteHost(w) 
# globals:  ATTR_NAME_HANA_SYNC_STATUS(w), ATTR_NAME_HANA_CLONE_STATE(w)
# globals:  DIR_EXECUTABLE(w), SAPSTARTSRV(w), SAPCONTROL(w), DIR_PROFILE(w), SAPSTARTPROFILE(w), LD_LIBRARY_PATH(w), PATH(w)
# globals:  LPA_DIRECTORY(w)
# saphana_init : Define global variables with default values, if optional parameters are not set
#
function saphana_init() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local myInstanceName=""
    local rc=$OCF_SUCCESS
    # two parameter models (for transition only)
    # OLD: InstanceName
    # NEW: SID InstanceNumber
    if [ -n "$OCF_RESKEY_SID" ]; then
       SID=$OCF_RESKEY_SID
       InstanceNr=$OCF_RESKEY_InstanceNumber
       myInstanceName="${SID}_HDB${InstanceNr}"
       InstanceName="HDB${InstanceNr}"
       super_ocf_log info "fhACT: Used new method to get SID ($SID) and InstanceNr ($InstanceNr)"
    else
       myInstanceName="$OCF_RESKEY_InstanceName"
       SID=$(echo "$myInstanceName" | cut -d_ -f1)
       InstanceName=$(echo "$myInstanceName" | cut -d_ -f2)
       InstanceNr=$(echo "$InstanceName" | sed 's/.*\([0-9][0-9]\)$/\1/')
       super_ocf_log info "fhACT: Used old method to get SID and InstanceNr"
    fi
    sid=$(echo "$SID" | tr [:upper:] [:lower:])
    sidadm="${sid}adm"
    SAPVIRHOST=${HOSTNAME}
    PreferSiteTakeover="$OCF_RESKEY_PREFER_SITE_TAKEOVER"
    meta_notify_master_uname="$OCF_RESKEY_CRM_meta_notify_master_uname"
    SAPHanaFilter="${OCF_RESKEY_SAPHanaFilter:-all}"
    LPA_DIRECTORY=/var/lib/SAPHanaRA
    LPA_ATTR=("lpa_${sid}_lpt" "reboot")
    super_ocf_log info "fhDBG: SID=$SID, sid=$sid, SIDInstanceName=$SIDInstanceName, InstanceName=$InstanceName, InstanceNr=$InstanceNr, SAPVIRHOST=$SAPVIRHOST meta_notify_master_uname=$meta_notify_master_uname"
    ocf_env=$(env | grep 'OCF_RESKEY_CRM')
    super_ocf_log info "fhDBG: OCF: $ocf_env"
    #
    ATTR_NAME_HANA_SYNC_STATUS=("hana_${sid}_sync_state" "reboot")  # SOK, SFAIL, UNKNOWN?
    ATTR_NAME_HANA_PRIMARY_AT=("hana_${sid}_primary_at"   "reboot") # Not really used
    ATTR_NAME_HANA_CLONE_STATE=("hana_${sid}_clone_state" "reboot") # UKNOWN?, DEMOTED, PROMOTED
    ATTR_NAME_HANA_REMOTEHOST=("hana_${sid}_remoteHost" "reboot")
    ATTR_NAME_HANA_SITE=("hana_${sid}_site" "reboot")
    ATTR_NAME_HANA_ROLES=("hana_${sid}_roles" "reboot")
    ATTR_NAME_HANA_SRMODE=("hana_${sid}_srmode" "reboot")
    ATTR_NAME_HANA_VHOST=("hana_${sid}_vhost" "reboot")
    ATTR_NAME_HANA_STATUS=("hana_${sid}_status" "reboot")
    #
    SCORING_TABLE_PREFERRED_SITE_TAKEOVER=(
       "[0-9]*:P:[^:]*:master .*  150"
       "[0-9]*:P:[^:]*:slave  .*   60"
       "[0-9]*:P:[^:]*:\?     .*    0"
       "[0-9]*:P:[^:]*:-     .*     0"
       "[0-9]*:S:[^:]*:master SOK    100"
       "[0-9]*:S:[^:]*:master SFAIL  -INFINITY"
       "[0-9]*:S:[^:]*:slave  SOK     10"
       "[0-9]*:S:[^:]*:slave  SFAIL  -INFINITY"
       "[0-9]*:S:[^:]*:\?     .*    0"
       "[0-9]*:S:[^:]*:-      .*    0"
       ".*                    .*   -1"
    )
    #
    DUPLICATE_PRIMARY_TIMEOUT="${OCF_RESKEY_DUPLICATE_PRIMARY_TIMEOUT:-7200}"
    super_ocf_log info "fhDBG: DUPLICATE_PRIMARY_TIMEOUT=$DUPLICATE_PRIMARY_TIMEOUT"
    #
    remoteHost=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_REMOTEHOST[@]});
    if [ -z "$remoteHost" ]; then
       remoteHosts=($(crm_node -l | awk '$3 == "member" { if ($2 != me) { print $2 }}' me=${HOSTNAME}))
       if [ ${#remoteHosts[@]} -eq 1 ]; then # we are a 2 node cluster, lets assume the other is the remote-host
          remoteHost=${remoteHosts[0]}
          super_ocf_log info "fhDBG: auto-guess remoteHost=$remoteHost"
       else
          super_ocf_log info "fhDBG: Could not auto-guess remoteHost out of list (${remoteHosts[@]})"
       fi
    fi
    #  ATTR_NAME_HANA_SITE
    sr_name=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_SITE[@]});
    super_ocf_log info "fhDBG: ATTR remoteHost=$remoteHost sr_name=$sr_name"

    sr_mode=$(get_hana_attribute "${HOSTNAME}" ${ATTR_NAME_HANA_SRMODE[@]})

    if [ -z "$sr_mode" ]; then
        sr_mode="sync"
    fi
    super_ocf_log info "fhDBG: sr_name=$sr_name, remoteHost=$remoteHost, sr_mode=$sr_mode"
    # optional OCF parameters, we try to guess which directories are correct
    if  [ -z "$OCF_RESKEY_DIR_EXECUTABLE" ]
    then
        if have_binary /usr/sap/$SID/$InstanceName/exe/sapstartsrv && have_binary /usr/sap/$SID/$InstanceName/exe/sapcontrol
        then
            DIR_EXECUTABLE="/usr/sap/$SID/$InstanceName/exe"
            SAPSTARTSRV="/usr/sap/$SID/$InstanceName/exe/sapstartsrv"
            SAPCONTROL="/usr/sap/$SID/$InstanceName/exe/sapcontrol"
        elif have_binary /usr/sap/$SID/SYS/exe/run/sapstartsrv && have_binary /usr/sap/$SID/SYS/exe/run/sapcontrol
        then
            DIR_EXECUTABLE="/usr/sap/$SID/SYS/exe/run"
            SAPSTARTSRV="/usr/sap/$SID/SYS/exe/run/sapstartsrv"
            SAPCONTROL="/usr/sap/$SID/SYS/exe/run/sapcontrol"
        fi
    else
        if have_binary "$OCF_RESKEY_DIR_EXECUTABLE/sapstartsrv" && have_binary "$OCF_RESKEY_DIR_EXECUTABLE/sapcontrol"
        then
            DIR_EXECUTABLE="$OCF_RESKEY_DIR_EXECUTABLE"
            SAPSTARTSRV="$OCF_RESKEY_DIR_EXECUTABLE/sapstartsrv"
            SAPCONTROL="$OCF_RESKEY_DIR_EXECUTABLE/sapcontrol"
        fi
    fi

    [ -z "$DIR_EXECUTABLE" ] && assert "Cannot find sapstartsrv and sapcontrol executable, please set DIR_EXECUTABLE parameter!"

    if [ -z "$OCF_RESKEY_DIR_PROFILE" ]
    then
        DIR_PROFILE="/usr/sap/$SID/SYS/profile"
    else
        DIR_PROFILE="$OCF_RESKEY_DIR_PROFILE"
    fi

    if [ -z "${OCF_RESKEY_INSTANCE_PROFILE}" ]
    then
        SAPSTARTPROFILE="$DIR_PROFILE/${SID}_${InstanceName}_${SAPVIRHOST}"
    else
        SAPSTARTPROFILE="$DIR_PROFILE/${OCF_RESKEY_INSTANCE_PROFILE}"
    fi

    if [ -z "$OCF_RESKEY_START_WAITTIME" ]
    then
        export OCF_RESKEY_START_WAITTIME=3600
    fi

    # as root user we need the library path to the SAP kernel to be able to call sapcontrol
    # check, if we already added DIR_EXECUTABLE at the beginning of LD_LIBRARY_PATH
    if [ "${LD_LIBRARY_PATH%%*:}" != "$DIR_EXECUTABLE" ]
    then
        LD_LIBRARY_PATH=$DIR_EXECUTABLE${LD_LIBRARY_PATH:+:}$LD_LIBRARY_PATH
        export LD_LIBRARY_PATH
    fi

    PATH=${PATH}:${DIR_EXECUTABLE}; export $PATH
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $OCF_SUCCESSs"


#############################
# TODO: RPRIO5: To be able to call landscapeHostConfig.py without su (so as root)
#export SAPSYSTEMNAME=ZLF
#export DIR_INSTANCE=/usr/sap/ZLF/HDB02
#export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$DIR_INSTANCE/exe:$DIR_INSTANCE/exe/Python/lib
#export PYTHONPATH=$DIR_INSTANCE/$HOST:$DIR_INSTANCE/exe/python_support:$DIR_INSTANCE/exe
#export PYTHONHOME=$DIR_INSTANCE/exe/Python
#export SAP_RETRIEVAL_PATH=$DIR_INSTANCE/$HOST
#export DIR_EXECUTABLE=$DIR_INSTANCE/exe
#############################
    return $OCF_SUCCESS
}

# function: check_secstore_users
# params:   USER1 USER2
# globals:  DIR_EXECUTABLE(r)
#
# TODO: PRIO3: Might be dropped, if we get a script for fetching the sync status
function check_secstore_users()
{
   super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local user1=$1
    local user2=$2
    local count
    local rc=1
    count=$($DIR_EXECUTABLE/hdbuserstore list | awk 'BEGIN {f=0} $0=="KEY " u1 {f++} $0=="KEY " u2 {f++} END {print f}' u1=$user1 u2=$user2)
    if [ "$count" -eq 2 ]; then
        rc=0
    else
        rc=2
    fi
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# function: check_sapstartsrv - check for sapstartsrv - optional start
# params:   -
# globals:  DIR_PROFILE(w), SAPSTARTPROFILE(r), SAPCONTROL(r), SID(r), InstanceName(r), InstanceNr(r), OCF_*(r)
# check_sapstartsrv : Before using sapcontrol we make sure that the sapstartsrv is running for the correct instance.
#                     We cannot use sapinit and the /usr/sap/sapservices file in case of an enquerep instance,
#                     because then we have two instances with the same instance number.
#
function check_sapstartsrv() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local restart=0
    local runninginst=""
    local rc=$OCF_SUCCESS
    local output=""

    if [ ! -S /tmp/.sapstream5${InstanceNr}13 ]; then
        super_ocf_log warn "fhACT sapstartsrv is not running for instance $SID-$InstanceName (no UDS), it will be started now"
        restart=1
    else
        output=$($SAPCONTROL -nr $InstanceNr -function ParameterValue INSTANCE_NAME -format script)
        if [ $? -eq 0 ]
        then
            runninginst=$(echo "$output" | grep '^0 : ' | cut -d' ' -f3)
            if [ "$runninginst" != "$InstanceName" ]
            then 
                super_ocf_log warn "fhACT sapstartsrv is running for instance $runninginst, that service will be killed"
                restart=1
            else
                output=$($SAPCONTROL -nr $InstanceNr -function AccessCheck Start)
                if [ $? -ne 0 ]; then
                    super_ocf_log warn "fhACT FAILED : sapcontrol -nr $InstanceNr -function AccessCheck Start ($(ls -ld1 /tmp/.sapstream5${InstanceNr}13))"
                    super_ocf_log warn "fhACT sapstartsrv will be restarted to try to solve this situation, otherwise please check sapstsartsrv setup (SAP Note 927637)"
                    restart=1
                fi
            fi
        else
            super_ocf_log warn "fhACT sapstartsrv is not running for instance $SID-$InstanceName, it will be started now"
            restart=1
        fi
    fi

    if [ -z "$runninginst" ]; then runninginst=$InstanceName; fi

    if [ $restart -eq 1 ]
    then

        if [ -d /usr/sap/$SID/SYS/profile/ ]
        then
            DIR_PROFILE="/usr/sap/$SID/SYS/profile"
        else
            assert "Expected /usr/sap/$SID/SYS/profile/ to be a directory, please set DIR_PROFILE parameter!"
        fi

        [ ! -r $SAPSTARTPROFILE ] && assert "Expected $SAPSTARTPROFILE to be the instance START profile, please set INSTANCE_PROFILE parameter!"

        pkill -9 -f "sapstartsrv.*$runninginst"

        # removing the unix domain socket files as they might have wrong permissions
        # or ownership - they will be recreated by sapstartsrv during next start
        rm -f /tmp/.sapstream5${InstanceNr}13
        rm -f /tmp/.sapstream5${InstanceNr}14

        $SAPSTARTSRV pf=$SAPSTARTPROFILE -D -u $sidadm

        # now make sure the daemon has been started and is able to respond
        local srvrc=1
        while [ $srvrc -eq 1 -a $(pgrep -f "sapstartsrv.*$runninginst" | wc -l) -gt 0 ]
        do
            sleep 1
            $SAPCONTROL -nr $InstanceNr -function GetProcessList > /dev/null 2>&1
            srvrc=$?
        done

        if [ $srvrc -ne 1 ]
        then
            super_ocf_log info "fhACT sapstartsrv for instance $SID-$InstanceName was restarted !"
            rc=$OCF_SUCCESS
        else
            super_ocf_log error "fhACT sapstartsrv for instance $SID-$InstanceName could not be started!"
            rc=$OCF_ERR_GENERIC
            ocf_is_probe && rc=$OCF_NOT_RUNNING
        fi
    fi

    return $rc
}

#
# function: cleanup_instance - remove resources from a crashed instance
# params:   -
# globals:  -
# cleanup_instance : remove resources (processes and shared memory) from a crashed instance)
#
function cleanup_instance() {
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local rc=0
# TODO: PRIO5: Check, if we need HANA cleanup procedure
#
# Do wee need to cleanup
#  - process list (kill/signal)
#  - ipc objects
#  - process-pid files and other files
  super_ocf_log warn "fhDBG: cleanup_instance currently not implemented"
  rc=0
  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
}

#
# function: saphana_hdbsql_check - query SR view
# params:   remote [local,remote]
# globals:  DIR_EXECUTABLE(r)
#
function saphana_hdbsql_check()
{
   super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
   local rc=1
   local remote=$1
   local secUser
#
# TODO: PRIO5: We could delete the remote check later, if we completely dropped the remore sql queries
#
   case "$remote" in 
        local* ) secUser="slehaLoc";;
        remote*) secUser="slehaRem";;
   esac
   super_ocf_log info "fhDBG: $DIR_EXECUTABLE/hdbsql -a -x -U $secUser 'select distinct REPLICATION_STATUS from SYS.M_SERVICE_REPLICATION'"
   timeout 300 $DIR_EXECUTABLE/hdbsql -a -x -U $secUser 'select distinct REPLICATION_STATUS from SYS.M_SERVICE_REPLICATION' 2>/dev/null 1>/dev/null; rc=$?
   super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
   return $rc
}

#
# function: check_for_primary - check if local SAP HANA is configured as primary
# params:   -
# globals:  HANA_STATE_PRIMARY(r), HANA_STATE_SECONDARY(r), HANA_STATE_DEFECT(r)
#
function check_for_primary() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
   node_status=$(check_for_primary_single) 
   super_ocf_log info "fhDBG: check_for_primary: node_status=$node_status"
   case "$node_status" in
       primary ) 
                  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = HANA_STATE_PRIMARY"
                  return $HANA_STATE_PRIMARY;;
       syncmem | sync | async )
                  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = HANA_STATE_SECONDARY"
                  return $HANA_STATE_SECONDARY;;
       none )     # have seen that mode on second side BEFEORE we registered it as replica
                  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = HANA_STATE_DEFECT"
                  return $HANA_STATE_DEFECT;;
       * )
		  super_ocf_log err "check_for_primary:  we didn't expect node_status to be: <$node_status>"
                  super_ocf_log err "check_for_primary: trying multiple times to get primary status"
                  for i in 1 2 3 4 5; do
                      node_status=$(check_for_primary_single)
                      super_ocf_log info "fhDBG: check_for_primary: (loop nr $i) node_status=$node_status"
                      case "$node_status" in
                           primary )
                                     super_ocf_log info "fhFLOW $FUNCNAME  -> return code = HANA_STATE_PRIMARY"
                                     return $HANA_STATE_PRIMARY;;
                           syncmem | sync | async )
                                     super_ocf_log info "fhFLOW $FUNCNAME  -> return code = HANA_STATE_SECONDARY"
                                     return $HANA_STATE_SECONDARY;;
                      esac
                      sleep 10
              done
   esac;
   super_ocf_log info "fhFLOW $FUNCNAME  -> return code = HANA_STATE_DEFECT"
   return $HANA_STATE_DEFECT
}

#
# function: check_for_primary_single - query hdbnsutil to get HANA primary/secondary status
# params:   -
# globals:  SID(r), LD_LIBRARY_PATH(r), PATH(r), DIR_EXECUTABLE(r)
#
function check_for_primary_single()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local node_full_status node_status
    local rc=0
    node_full_status=$(su - ${sidadm} -c "LD_LIBRARY_PATH=$LD_LIBRARY_PATH $DIR_EXECUTABLE/hdbnsutil -sr_state" 2>/dev/null )
    node_status=$(echo "$node_full_status" | awk '$1=="mode:" {print $2}')
    echo "$node_status"
    return $rc
}

#
# function: analyze_hana_sync_status - query and check hana system replication status
# params:   -
# globals:  DIR_EXECUTABLE(r), remoteHost(r)
# get the HANA sync status
# 
function analyze_hana_sync_status()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local hana_sync_status="" what_does_the_chamelion_say=""
    local secUser="slehaLoc"
    local rc=0
    local sqlrc=0
    local query_state='select distinct REPLICATION_STATUS from SYS.M_SERVICE_REPLICATION'
    local query_secondaries='select distinct  SECONDARY_HOST from SYS.M_SERVICE_REPLICATION'
    local query_failed_secondaries="select distinct SECONDARY_HOST from SYS.M_SERVICE_REPLICATION  where SECONDARY_SITE_NAME = (select distinct  SECONDARY_SITE_NAME from SYS.M_SERVICE_REPLICATION WHERE REPLICATION_STATUS != 'ACTIVE')"
    local all_cluster_hosts all_secondary_hosts all_broken_secondaries
    hana_sync_status=$(timeout 60 $DIR_EXECUTABLE/hdbsql -a -x -U $secUser  $query_state); sqlrc=$?
    hana_sync_status=$(echo $hana_sync_status | dequote)
    super_ocf_log info "fhDBG: hdbsql rc=$sqlrc hana_sync_status=$hana_sync_status<"
    if [ "$sqlrc" -eq 0 -a "$hana_sync_status" != "" ]; then
        #
        # UNKNOWN, ACTIVE, ERROR, INITIALIZING
        #
        if [ "${hana_sync_status}" == "ACTIVE" ]; then
            set_hana_attribute "$remoteHost" "SOK" ${ATTR_NAME_HANA_SYNC_STATUS[@]}
        else
            super_ocf_log warn "HANA SYNC STATUS is: ${hana_sync_status}"
            set_hana_attribute "$remoteHost" "SFAIL" ${ATTR_NAME_HANA_SYNC_STATUS[@]}
        fi

        # first get a list of all secondary hosts, than a list of all secondary hosts, if the is ANY failure at this site
        #    TODO: PRIO9: for first we assume there is only ONE secondary site (like ROT)
        #    TODO: PRIO2: should we loop over all cluster nodes fetching their roles-attribute? To minimize sql-queries?
        #
        all_secondary_hosts=$(timeout 60 hdbsql -a -x -U $secUser $query_secondaries ); sqlrc=$?
        if [ "$sqlrc" -eq 0 ]; then
            all_broken_secondary_hosts=$(timeout 60 hdbsql -a -x -U $secUser $query_failed_secondaries); sqlrc=$?
            all_broken_secondary_hosts=$(echo $all_broken_secondary_hosts | dequote); sqlrc=$?
            if  [ "$sqlrc" -eq 0 ]; then                 
                 if [ -n "$all_broken_secondary_hosts" ]; then
                     #
                     # we have a broken secondary site - set all hosts to "SFAIL"
                     #
                     for n in $all_broken_secondary_hosts; do
                         set_hana_attribute "$n" "SFAIL" ${ATTR_NAME_HANA_SYNC_STATUS[@]}
                     done
                 else 
                     #
                     # we have an ACTIVE secondary site - set all hosts to "SOK"
                     #
                     for n in $all_secondary_hosts; do
                         set_hana_attribute "$n" "SOK" ${ATTR_NAME_HANA_SYNC_STATUS[@]}
                     done
                 fi
            else
                # TODO: PRIO1: ASK - Better would be to think about a  trigger which rizes whenever the sync-status changes (with status like OK, FAIL)
                # TODO: PRIO1: We should NOT set SFAIL, if HDB is exactly broken now
                #       When HDB breaks during monitor this could prevent a prositive remote failover
                #       Should we really set all cluster hosts to SFAIL? Not only secondaries (by attribute)
                #       should we loop over all cluster nodes fetching their roles-attribute?
                #       
                super_ocf_log warn "Was not able to fetch HANA list of broken secondary hosts - set sync status to SFAIL for ALL cluster hosts BUT not myself"
                all_cluster_hosts=$(crm_node -Q -l -A | awk '($3 == "member") && ($2 != lh)  { print $2 }' lh=${HOSTNAME})
                for n in $all_cluster_hosts; do
                    set_hana_attribute "$n" "SFAIL" ${ATTR_NAME_HANA_SYNC_STATUS[@]}
                done
            fi
        else
            # TODO: PRIO1: We should NOT set SFAIL, if HDB is exactly broken now
            #       When HDB breaks during monitor this could prevent a prositive remote failover
            #
            super_ocf_log warn "Was not able to fetch HANA secondary hosts - set sync status to SFAIL for ALL cluster hosts"
            all_cluster_hosts=$(crm_node -Q -l -A | awk '($3 == "member") && ($2 != lh)  { print $2 }' lh=${HOSTNAME})
            for n in $all_cluster_hosts; do
                set_hana_attribute "$n" "SFAIL" ${ATTR_NAME_HANA_SYNC_STATUS[@]}
            done
        fi                  
    else
            # TODO: PRIO1: We should NOT set SFAIL, if HDB is exactly broken now
            #       When HDB breaks during monitor this could prevent a prositive remote failover
        super_ocf_log warn "Was not able to fetch HANA SYNC STATUS - set sync status to SFAIL for ALL cluster hosts"
        all_cluster_hosts=$(crm_node -Q -l -A | awk '($3 == "member") && ($2 != lh)  { print $2 }' lh=${HOSTNAME})
        for n in $all_cluster_hosts; do
            set_hana_attribute "$n" "SFAIL" ${ATTR_NAME_HANA_SYNC_STATUS[@]}
        done
    fi  
    return $rc
}

#
# function: get_hana_landscape_status - figure out hana ladscape status
# params:   -
# globals:  sidadm(r), DIR_EXECUTABLE(r)
# get the HANA landscape status
#
function get_hana_landscape_status()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
    #
    su - $sidadm -c "python $DIR_EXECUTABLE/python_support/landscapeHostConfiguration.py" 1>/dev/null 2>/dev/null; rc=$?
    # ls_rc:
    # 0 : FATAL  -> (do nothing -> admin must solve that!)
    # 1 : ERROR  -> HANA is Down (failes or down instance -> takeover if running master/primary fails)
    # 2 : WARN   -> HANA is UP
    # 3 : INFO   -> HANA is UP
    # 4 : OK     -> HANA is UP

    # DONE: ASK: What to do on landscapeHostConfiguration return code 2? ANSWER: NO TAKEOVER
    # DONE: ASK: Can we defitive rely on landscapeHostConfiguration.py? ANSWER: YES
    return $rc;
}

#
# function: register_hana_secondary - register local hana as secondary to the other site
# params:   -
# globals:  sidadm(r), remoteHost(r), InstanceNr(r), sr_mode(r), sr_name(r)
# register_hana_secondary
#
function register_hana_secondary()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=2;
    local remoteInstance="";
    # HANA nedds to be stopped to register!
    # as sidadm
    # hdbnsutil -sr_register --remoteHost=lv9041 --remoteInstance=42 --mode=syncmem --name=ROT
    # --remoteHost=  this is the (new) primary host
    # --remoteInstance= this is the (new) primaries instance number - do we assume the same number?
    # --name= this is the local(!) site name 

    # REMARK: For first we assume both SIDs and InstanceNumbers are equal - so we could use our values
  
    remoteInstance=$InstanceNr

    super_ocf_log info "fhACT: REGISTER: hdbnsutil -sr_register --remoteHost=$remoteHost --remoteInstance=$remoteInstance --mode=$sr_mode --name=$sr_name"
    su - $sidadm -c "hdbnsutil -sr_register --remoteHost=$remoteHost --remoteInstance=$remoteInstance --mode=$sr_mode --name=$sr_name"
#
# TODO: PRIO2: laut Alex Krauth gibt das Konstruct immer rc=2 zurück -> prüfen
#
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc;
}

#
# function: saphana_notify_log_values - log notify variables (also as tuples)
# params:   variable-names variable-values
# globals:  -
#
function saphana_notify_log_values()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
    local name=$1
    local value=$2
    local separator="/"
    
    if [ -n "$value" ]; then
       if [ "$(echo $value | tr -d ' ')" != "$separator" ]; then
		super_ocf_log info "fhDBG: saphana_notify: $name $value"
          
       fi 
    fi
    return $rc
} 


#
#############################################################################
#
# function: saphana_start - start a hana instance
# params:   -
# globals:  TBD
# saphana_start : Start the SAP HANA instance
#
function saphana_start() {
  
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"

  local rc=$OCF_NOT_RUNNING
  local output=""
  local loopcount=0  

  while [ $loopcount -lt 2 ]
  do
    loopcount=$(($loopcount + 1))

    check_sapstartsrv
    rc=$?
    #
    # TODO: ASK: PRIO5: For SCALE-OUT - do we need to use an other call like StartSystem? Or better to use the HDB command?
    #
    if [ $rc -eq $OCF_SUCCESS ]; then
      output=$($SAPCONTROL -nr $InstanceNr -function Start)
      rc=$?
      super_ocf_log info "fhACT Starting SAPHANA Instance $SID-$InstanceName: $output"
    fi

    if [ $rc -ne 0 ]
    then
      super_ocf_log err "fhACT SAPHANA Instance $SID-$InstanceName start failed."
      return $OCF_ERR_GENERIC
    fi

    local startrc=1
    while [ $startrc -gt 0 ]
    do
      local waittime_start=$(date +%s)
      output=$($SAPCONTROL -nr $InstanceNr -function WaitforStarted $OCF_RESKEY_START_WAITTIME 10)
      startrc=$?
      local waittime_stop=$(date +%s)

      if [ $startrc -ne 0 ]
      then
        if [ $(($waittime_stop - $waittime_start)) -ge $OCF_RESKEY_START_WAITTIME ]
        then
          saphana_monitor NOLOG
          if [ $? -eq $OCF_SUCCESS ]
          then
            output="START_WAITTIME ($OCF_RESKEY_START_WAITTIME) has elapsed, but instance monitor returned SUCCESS. Instance considered running."
            startrc=0; loopcount=2
          fi
        else
          loopcount=2
          startrc=-1
        fi
      else
        loopcount=2
      fi
    done
  done

  if [ $startrc -eq 0 ]
  then
    super_ocf_log info "fhACT:  SAP Instance $SID-$InstanceName started: $output"
    rc=$OCF_SUCCESS
  else
    super_ocf_log err "SAP Instance $SID-$InstanceName start failed: $output"
    rc=$OCF_NOT_RUNNING
  fi

  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
  return $rc
}


#
# function: saphana_recover - recover - cleanup and (re)start a hana instance
# params:   -
# globals:  -
# saphana_recover: Try startup of failed instance by cleaning up resources
#
function saphana_recover() {
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local rc=0
  cleanup_instance
  saphana_start
  rc=$?
  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
  return $rc
}


#
# function: saphana_stop - stop a hana instance
# params:   -
# globals:  OCF_*(r), SAPCONTROL(r), SID(r), InstanceName(r)
# saphana_stop: Stop the SAP instance
#
function saphana_stop() {
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local output=""
  local rc=0

  check_sapstartsrv; rc=$?
  if [ $rc -eq $OCF_SUCCESS ]; then
    output=$($SAPCONTROL -nr $InstanceNr -function Stop)
    rc=$?
    super_ocf_log info "fhACT: Stopping SAP Instance $SID-$InstanceName: $output"
  fi

  if [ $rc -eq 0 ]
  then
    output=$($SAPCONTROL -nr $InstanceNr -function WaitforStopped 3600 1)
    if [ $? -eq 0 ]
    then
      super_ocf_log info "fhACT: SAP Instance $SID-$InstanceName stopped: $output"
      rc=$OCF_SUCCESS
    else
      super_ocf_log err "fhACT: SAP Instance $SID-$InstanceName stop failed: $output"
      rc=$OCF_ERR_GENERIC
    fi
  else
    super_ocf_log err "fhACT: SAP Instance $SID-$InstanceName stop failed: $output"
    rc=$OCF_ERR_GENERIC
  fi


  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
  return $rc
}


#
# function: saphana_monitor - monitor a hana instance
# params:   MONLOG
# globals:  OCF_*(r), SAPCONTROL(r), InstanveNr(r)
# saphana_monitor: Can the given SAP instance do anything useful?
#
function saphana_monitor() {
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local MONLOG=$1
  local rc=0

  check_sapstartsrv
  rc=$?

  if [ $rc -eq $OCF_SUCCESS ]
  then
    local count=0
    local SERVNO
    local output

#
# TODO: PRIO2: Check - completely switch-over to landscape script?
#
    output=$($SAPCONTROL -nr $InstanceNr -function GetProcessList -format script)

    # we have to parse the output, because the returncode doesn't tell anything about the instance status
    for SERVNO in $(echo "$output" | grep '^[0-9] ' | cut -d' ' -f1 | sort -u)
    do
      local COLOR=$(echo "$output" | grep "^$SERVNO dispstatus: " | cut -d' ' -f3)
      local SERVICE=$(echo "$output" | grep "^$SERVNO name: " | cut -d' ' -f3)
      local STATE=0
      local SEARCH

      case $COLOR in
        GREEN|YELLOW)       STATE=$OCF_SUCCESS;;
        *)                  STATE=$OCF_NOT_RUNNING;;
      esac 

#
# TODO: PRIO2: Check - completely switch-over to landscape script?
#       OCF_RESKEY_MONITOR_SERVICES wird nicht (mehr) gesetzt, also entweder wieder setzen oder variable hier entfernen
#
      SEARCH=$(echo "$OCF_RESKEY_MONITOR_SERVICES" | sed 's/\+/\\\+/g' | sed 's/\./\\\./g')
      if [ $(echo "$SERVICE" | egrep -c "$SEARCH") -eq 1 ]
      then
          if [ $STATE -eq $OCF_NOT_RUNNING ]
          then
            [ "$MONLOG" != "NOLOG" ] && super_ocf_log err "SAP instance service $SERVICE is not running (status $COLOR) !"
            rc=$STATE
          fi
          count=1
      fi
    done

    if [ $count -eq 0 -a $rc -eq $OCF_SUCCESS ]
    then
      if ocf_is_probe
      then
        rc=$OCF_NOT_RUNNING
      else
        [ "$MONLOG" != "NOLOG" ] && super_ocf_log err "The SAP instance does not run any services which this RA could monitor!"
        rc=$OCF_ERR_GENERIC
      fi
    fi
  fi
 
  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc" 
  return $rc
}


#
# function: saphana_status - get status of a hana instance (os tools only)
# params:   -
# globals:  SID(r), InstanceName(r), OCF_*(r), sidarm(r)
# saphana_status: Lightweight check of SAP instance only with OS tools
#
function saphana_status() {
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local pid
  local pids
  local killsap="/usr/sap/$SID/$InstanceName/${HOSTNAME}/trace/kill.sap"

echo "fhDBD: saphana_status: SID=$SID"
echo "fhDBD: saphana_status: InstanceName=$InstanceName"

  [ ! -f ${killsap} ] && return $OCF_NOT_RUNNING
  pids=$(awk '/^kill -[0-9]/ {print $3}' ${killsap})
  for pid in $pids
  do
    [ $(pgrep -f -U $sidadm $InstanceName | grep -c $pid) -gt 0 ] && return $OCF_SUCCESS
  done
  return $OCF_NOT_RUNNING
}


#
# function: saphana_validate - validation of (some) variables/parameters
# params:   -
# globals:  OCF_*(r), SID(r), InstanceName(r), InstanceNr(r), SAPVIRHOST(r)
# saphana_validate: Check the symantic of the input parameters 
#
function saphana_validate() {
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local rc=$OCF_SUCCESS
  #
  # SID is Alpha-AlphaNumeric-Alphanumeric?
  #
  if [ $(echo "$SID" | grep -c '^[A-Z][A-Z0-9][A-Z0-9]$') -ne 1 ]
  then
    super_ocf_log err "Parsing instance profile name: '$SID' is not a valid system ID!"
    rc=$OCF_ERR_ARGS
  fi
  #
  # InstanceNr is a two-Digit?
  #
  if [ $(echo "$InstanceNr" | grep -c '^[0-9][0-9]$') -ne 1 ]
  then
    super_ocf_log err "Parsing instance profile name: '$InstanceNr' is not a valid instance number!"
    rc=$OCF_ERR_ARGS
  fi
  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
  return $rc
}

#
# function: saphana_start_primary - handle startup of PRIMARY in M/S
# params:
# globals: OCF_*(r), TBD
#
function saphana_start_primary()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
	local primary_status sync_attr score_master rc=$OCF_NOT_RUNNING
    local lss sqlrc;
    local rc=0
    local lpa_dec=4
    local lpa_advice=""
    #
    # we will be a master (PRIMARY) so checking, if the is an OTHER master
    #
    super_ocf_log info "fhDBG: saphana_primary - check_for_primary reports HANA_STATE_PRIMARY"
    # 
    lpa_check_lpt_status; lpa_dec=$?
    get_hana_landscape_status; lss=$?
    my_role=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_ROLES[@]})
    my_sync=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_SYNC_STATUS[@]})
    case "$lpa_dec" in
        0 ) # LPA says start-up
            lpa_advice="start"
            ;;
        1)  # LPA says register!
            lpa_advice="register"
            ;;
        2)  # LPA says wait for second LPT
            lpa_advice="wait"
            ;;
        3 | 4 ) # LPA says something is completely wrong - FAIL resource
            lpa_advice="fail"
            ;;
        * ) # LPA failed with an unkonown status - FAIL resource
            lpa_advice="fail"
            ;;
    esac
    
    # DONE: PRIO2: Do we need to differ 0 and 1 here? While 0 is a fatal SAP error, 1 for down/error
    if [ $lss -eq 0 ]; then
       super_ocf_log err "fhDEC: get_hana_landscape_status reports FATAL"
       # TODO: PRIO1: what to do for lss=0?
       rc=$OCF_ERR_GENERIC
    fi
    case "$lpa_advice" in
        start )  # process a normal START
            case "$lss" in
                2 | 3 | 4 ) # as landcape says we are up - just set the scores and return code
                    super_ocf_log info "fhLPA: landcape: UP, LPA: start ==> keep running"
                    rc=$OCF_SUCCSESS
                    ;;
                1 ) # landcape says we are down, lets start and adjust scores and return code
                    super_ocf_log info "fhLPA: landcape: DOWN, LPA: start ==> start instance"
                    saphana_start
                    rc=$?                    
                    ;;
            esac
            scoring_crm_master "$my_role" "$my_sync"
            ;;
        register ) # process a REGISTER
            case "$lss" in
                2 | 3 | 4 ) # upps we are up - but shoudn't? - we could not register with started HDB
                    # TODO: PRIO1: check if this reaction is correct - tell cluster about failed start
                    super_ocf_log info "fhLPA: landcape: UP, LPA: register ==> take down"
                    set_crm_master -inf
                    rc=$OCF_NOT_RUNNING 
                    ;;
                1 ) # lets try to register
                    # TODO: PRIO2: Like Action in start_secondary
                    super_ocf_log info "fhLPA: landcape: DOWN, LPA: register ==> try to register"
                    super_ocf_log info "fhDEC: ===> AN OTHER HANA IS AVAILABLE ==> LETS REGISTER"
                    set_crm_master  0
                    if forever_wait_for_primary_master 1; then
                        register_hana_secondary 
                        check_for_primary; primary_status=$?
                        if [ $primary_status -eq $HANA_STATE_SECONDARY ]; then
                            super_ocf_log info "fhACT: Register successful"
                            lpa_push_lpt 10
                            lpa_set_lpt  10
                            set_crm_master  0
                            saphana_start_secondary
                            rc=$?
                            lpa_set_lpt  30
                        else
                            super_ocf_log err "Register failed"
                            rc=$OCF_NOT_RUNNING
                        fi                                         
                    else
                        # lets check next monitor, if we can register
                        rc=$OCF_SUCCESS
                    fi
                    ;;
            esac
            ;;
        wait )  # process a WAIT
            case "$lss" in
                2 | 3 | 4 ) # as we ARE up we just keep it up
                    # TODO: PRIO1: I now change from "just keep it up to take that down"
                    # TODO: PRIO2: Check, why this should happen and if we need special processing
                    set_crm_master -9000
                    #scoring_crm_master "$my_role" "$my_sync"
                    # TODO: PRIO1: OCF_SUCCSESS, OCF_NOT_RUNNING or OCF_ERR_xxxx ?
                    rc=$OCF_ERR_GENERIC
                    ;;
                1 ) # we are down, so we should wait --> followup in next monitor
                    super_ocf_log info "fhLPA: landcape: DOWN, LPA: wait ==> keep waiting"
                    # TODO: PRIO1: Check, if WAITING is correct here
                    set_hana_attribute ${HOSTNAME} "WAITING" ${ATTR_NAME_HANA_CLONE_STATE[@]}
                    set_crm_master -9000
                    rc=$OCF_SUCCSESS
                    ;;
            esac
            ;;
        fail )   # process a lpa FAIL
            super_ocf_log info "fhLPA: LPA reports FAIL"
            set_crm_master -inf
            rc=$OCF_NOT_RUNNING 
            ;;
    esac
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# check_for_primary_master
# params: -
# globals: ATTR_NAME_HANA_ROLES[@], HOSTNAME
#
check_for_primary_master()
{
    super_ocf_log info "fhflow: $FUNCNAME $1 $2 $3 $4"
    local rc=1
    local otherHosts
    local ch ch_role
    #
    # get actual list of cluster members
    # 
    otherHosts=($(crm_node -l | awk '$3 == "member" { if ($2 != me) { print $2 }}' me=${HOSTNAME}))
    if [ -n "$otherHosts" ]; then
        for ch in ${otherHosts[@]}; do
            if [ $rc -eq 1 ]; then
                ch_role=$(get_hana_attribute ${ch} ${ATTR_NAME_HANA_ROLES[@]})
                grep '[0-9]*:P:[^:]*:master:' <<< $ch_role && rc=0
            fi
        done
    fi 
    super_ocf_log info "fhflow: $FUNCNAME rc=$rc"
    return $rc
}

#
# forever_wait_for_primary_master: wait forever till a running primary master is shown in attributes
# params: optional: loop count ;-) , so not really "forever"
# globals: -
#
forever_wait_for_primary_master()
{
    local wait=1
    local rc=1
    local loops=${1:-0}
    local count=0
    super_ocf_log info "fhflow: $FUNCNAME $1 $2 $3 $4"

    #
    # hana_ndb_roles=primary:master1:master:worker:master
    #
    while [ "$wait" -eq 1 ]; do
        if check_for_primary_master; then
           wait=0
           rc=0
        else
           if [ $loops -gt 0 ]; then
              (( count++ ))
              if [ $count -gt $loops ]; then
                 wait=0
                 rc=1
              fi
           fi
           sleep 10
        fi
    done
    super_ocf_log info "fhflow: $FUNCNAME rc=1"
    return $rc
}

#
# function: saphana_start_secondary - handle startup of PRIMARY in M/S
# params:
# globals: OCF_*(r), TBD
#
function saphana_start_secondary()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
	local primary_status sync_attr score_master rc=$OCF_NOT_RUNNING
    local sqlrc;
    set_crm_master 0
    #
    ####### LPA - begin
    #
    lpa_push_lpt 10
    lpa_set_lpt  10
    # 
    ####### LPA - end
    # 
    #
    # we would be slave (secondary)
    # we first need to check, if there are Master Nodes, because the Scecondary only starts
    # successfuly, if the Primary is available. Thatfore we mark the Secondary as "WAITING"
    # TODO: PRIO3: forever_wait_for_primary_master 10 is just a test value: 10 loops x10 seconds than go to WAITING
    # TODO: PRIO3: rename 'forever_wait_for_primary_master' to match better the use case ("wait_some_time")
    #
    super_ocf_log info "fhDBG: wait for promoted side"
    if forever_wait_for_primary_master 10; then
       saphana_start; rc=$?
    else
       super_ocf_log info "fhDBG: forever_wait_for_primary_master (too much loops) -> WAITING"
       set_hana_attribute ${HOSTNAME} "WAITING" ${ATTR_NAME_HANA_CLONE_STATE[@]}
       set_crm_master -INFINITY
       rc=$OCF_SUCCSESS
    fi
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# function: lpa_get_lpt - get lpt from cluster
# params:   NODE
# globals:  LPA_ATTR(r), TBD
# output:   LPT
# rc:       rc=0: OK, rc=1: TBD, rc=2: ERROR
#
function lpa_get_lpt() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=1
    local node=$1
    local lpt=""
    lpt=$(get_hana_attribute ${node} ${LPA_ATTR[@]})
    if [ -n "$lpt" ]; then
        rc=0
        echo $lpt
    else
        rc=2
    fi
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc    
}

#
# function: lpa_set_lpt - set lpt in cluster
# params:   LPT
# globals:  LPA_ATTR(r), HOSTNAME(r), TBD
# rc:       rc=0: OK, rc=1: TBD, rc=2: ERROR
#
function lpa_set_lpt() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=1
    local crm_rc=1
    local lpt=$1
    local clpt=-1
    set_hana_attribute ${HOSTNAME} "$lpt" ${LPA_ATTR[@]}; crm_rc=$?
    clpt=$(lpa_get_lpt $HOSTNAME)
    if [ "$lpt" != "$clpt" ]; then
        rc=2
    else
        rc=0
    fi
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc    
}

#
# function: lpa_pull_lpt - fetch lpt from file
# params:   TBD
# globals:  LPA_DIRECTORY(r)
# output:   LPT
# rc:       rc=0: OK, rc=1: TBD, rc=2: ERROR
#
function lpa_pull_lpt() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=1
    local lpt=-1
    local readrest=0
    local lpa_file=$LPA_DIRECTORY/lpa_${sid}_${HOSTNAME}
    read lpt readrest <<<$(cat $lpa_file) # exactly load first word from file to lpt
    if [ -n "$lpt" ]; then
        rc=0
        echo $lpt
    else
        rc=2
    fi
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc    
}

#
# function: lpa_push_lpt - put lpt to file
# params:   LPT
# globals:  LPA_DIRECTORY(r)
# output:   --
# rc:       rc=0: OK, rc=1: TBD, rc=2: ERROR
#
function lpa_push_lpt() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local lpt=$1
    local clpt=-1
    local rc=1
    local lpa_file=$LPA_DIRECTORY/lpa_${sid}_${HOSTNAME}
    #
    mkdir -p $LPA_DIRECTORY
    echo "$lpt" > $lpa_file
    clpt=$(lpa_pull_lpt); lpt_rc=$?
    if [ "$clpt" != "$lpt" -o "$lpt_rc" -ne 0 ]; then
        rc=2
    else
        rc=0
    fi     
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc    
}

#
# function: lpa_init_lpt - initialize local lpt, if needed
# params:   HANA_STATE
# globals:  HANA_STATE_*(r), LPA_DIRECTORY(r), sid(r), HOSTNAME(r), TBD
# lpa_init_lpt
#
# Returncodes:
#    rc=0: OK,  rc=1 TBD,  rc=2: ERROR
#
# Initializing (if NO local LPT-file):
#    SECONDARY sets to 0
#    PRIMARY   sets to 1
# 
function lpa_init_lpt() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=1
    local LPTloc=-1
    local LPTrem=-1
    local hana_state=$1
    local lpa_file=$LPA_DIRECTORY/lpa_${sid}_${HOSTNAME}
    mkdir -p $LPA_DIRECTORY
    LPTloc=$(lpa_get_lpt ${HOSTNAME}) || LPTloc=$(lpa_pull_lpt) || \
        if   [ "$hana_state" -eq "$HANA_STATE_PRIMARY" ];  then    # Initialize for Primary
            # init primary
            lpa_push_lpt "20"; rc=$?
        elif [ "$hana_state" -eq "$HANA_STATE_SECONDARY" ]; then   # Initialize for Secondary
            # init secondary
            lpa_push_lpt "10"; rc=$?
        else
            rc=2                                   
        fi
    lpa_set_lpt $LPTloc
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc    
}

#
# function: lpa_check_lpt_status - start a hana clone instance
# params:   TBD
# globals:  TBD
# lpa_check_lpt_status
#
# Returncodes:
#
# Initializing (if NO local LPT-file):
#    SECONDARY sets to 10
#    PRIMARY   sets to 20
#
#### NEW (TODO PRIO1)
#
#    LPRlocal OR LPTremore ARE real lpt (>1000)
#        THEN:
#            Bigger LPR wins, if delta-gab is OK
#               LPTlocal >> LPTremore ===> rc=0 (start) 
#               LPTRemote >> LPTlocal ===> rc=1 (register)
#            Stalemate in all other cases ==> STALEMATE-HANDLING ===> rc=2 (wait)
#    LPRlocal AND LPTremore ARE NOT real lpt (<=1000)
#        THEN:
#            Bigger LPT wins
#               LPTlocal > LPTremore ===> rc=0 (start) 
#               LPTRemote > LPTlocal ===> rc=1 (register)
#            Stalemate in all other cases ==> STALEMATE-HANDLING ===> rc=2 (wait)
#    LPTRemote is not initialized (0)
#        THEN:
#            WAIT ==> like STALEMATE-HANDLING ===> rc=2 (wait)
#    
function lpa_check_lpt_status() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
    local LPTloc=-1
    local LPTrem=-1
    local LPTMark=1000
    local delta=0
    #
    # First GET LPT from ATTR-FILE-DEFAULT
    #
    LPTloc=$(lpa_get_lpt $HOSTNAME); lparc=$?   # ATTR
    if [ "$lparc" -ne 0 ]; then
        # as a fallback try to fetch the value from external status file
        LPTloc=$(lpa_pull_lpt);                 # FILE
        lparc=$?
        if [ -z "$LPTloc" -o "$LPTloc" -eq -1 -o "$lparc" -ne 0 ]; then
            # last option - try to initialize as PRIMARY
            lpa_push_lpt 20
            lpa_set_lpt  20
            LPTloc=20                           # DEFAULT
        fi
    fi
    LPTrem=$(lpa_get_lpt $remoteHost); lparc=$?
    if [ $lparc -ne 0 ]; then
        # LPT of the other node could not be evaluated - LPA says WAIT
        super_ocf_log info "fhDBG: LPA: LPTloc=$LPTloc, LPTrem undefined => WAIT"
        rc=2
    else
        super_ocf_log info "fhDBG: LPA: LPTloc ($LPTloc) LPTrem ($LPTrem) delta ($delta)"
        if [ $LPTloc -lt $LPTMark -a $LPTrem -lt $LPTMark ]; then
           delta=0   # both lpts are not a real timestamp so just take the greater one
        else
           delta=$DUPLICATE_PRIMARY_TIMEOUT   # at least one of the lpts is a real timestamp so include delta-gap
        fi
        if (( delta < LPTloc - LPTrem )); then 
            # We are the winner - LPA says STARTUP
            super_ocf_log info "fhDBG: LPA: LPTloc wins $LPTloc > $LPTrem + $delta => START"
            rc=0
        elif (( delta < LPTrem - LPTloc )); then 
            # The other one has won - LPA says REGISTER
            super_ocf_log info "fhDBG: LPA: LPTrem wins $LPTrem > $LPTloc + $delta => REGISTER"
            rc=1
        else                                     
            super_ocf_log info "fhDBG: LPA: Difference between LPTloc and LPTrem is less than delta ($delta) => WAIT"
            # TODO: PRIO1: ADD STALEMATE-HANDLING HERE
            rc=2
        fi        
    fi    
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc    
}

#
# function: saphana_start_clone - start a hana clone instance
# params:   -
# globals:  TBD
# saphana_start_clone
#
function saphana_start_clone() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
	local primary_status sync_attr score_master rc=$OCF_NOT_RUNNING
    local sqlrc;
    local chkusr;
    # DONE: ASK: Can we assume that also SAP "needs" cluster nodes in time-sync? Answer: Yes, they need to be in time sync.
    # DONE: PRIO5: ASK: which minimal grants/permissions does the dbuser need to access the sync view? A: we will get a script
    #
    check_secstore_users SLEHALOC SLEHAREM; chkusr=$?
    if [ $chkusr -ne 0 ]; then
         super_ocf_log err  "fhDEC: Secure store users are missing (see best practice manual how to setup the users)"
         rc=$OCF_ERR_CONFIGURED
    else
        set_hana_attribute ${HOSTNAME} "DEMOTED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
        check_for_primary; primary_status=$?
        if [ $primary_status -eq $HANA_STATE_PRIMARY ]; then
            saphana_start_primary; rc=$?
        else 
            saphana_start_secondary; rc=$?
            lpa_set_lpt  30
        fi 
    fi
    return $rc
}

#
# function: saphana_stop_clone - stop a hana clone instance
# params:   -
# globals:  HOSTNAME(r), HANA_STATE_*(r)
# saphana_stop_clone
#
function saphana_stop_clone() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=0
    local primary_status="x"
    set_hana_attribute ${HOSTNAME} "UNDEFINED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
    check_for_primary; primary_status=$?
    if [ $primary_status -eq $HANA_STATE_SECONDARY ]; then
        lpa_set_lpt  10
    fi 
    saphana_stop; rc=$?
    return $rc
}

#
# function: saphana_monitor_primary - monitor a hana clone instance
# params:   -
# globals:  HANA_STATE_*(r), remoteHost, TBD
#
function saphana_monitor_primary()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
	local rc=$OCF_ERR_GENERIC
	local promoted=0
    local init_attribute=0
    local LPTloc=-1
    local lparc=4
    local lss
    local remoreSync=""
    local my_role=""
    #
    # OK, we are running/are configured as HANA PRIMARY
    #
    super_ocf_log info "fhDBG saphana_monitor_clone: HANA_STATE_PRIMARY"
    #
    ##### CHECK, IF WE ARE DEMOTED (CLUSTER NODE ATTRIBUTE)
    #
    promote_attr=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_CLONE_STATE[@]})
    super_ocf_log info "fhDBG saphana_monitor_clone: $ATTR_NAME_HANA_CLONE_STATE=$promote_attr"
    if [ -z "$promote_attr" ]; then
        init_attribute=1
        promoted=0;
    else
        case "$promote_attr" in
            PROMOTED )
                promoted=1;
                ;;
            DEMOTED )
                promoted=0;
                ;;
            WAITING )  
                # DONE: lpa_check_lpt_status to come out of here :)
                # TODO: PRIO1: CHECK IF THE FIX FOR COMING OUT OF WAITING IS CORRECT
                get_hana_landscape_status; lss=$?
                if [ $lss -ge 2 ]; then
                    # seems admin already decided that for us? -> we are running - set DEMOTED
                    promoted=0;
                    LPTloc=$(date '+%s')
                    lpa_set_lpt $LPTloc
                fi
                lpa_check_lpt_status; lparc=$?
                if [ $lparc -ne 2 ]; then
                    # lpa - no need to wait any longer - lets try a new start
                    saphana_start_clone
                    rc=$?
                    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
                    return $rc
                else
                    lpa_init_lpt $HANA_STATE_PRIMARY
                    # still waiting for second site to report lpa-lpt
                    super_ocf_log info "fhLPA: Still waiting for remote site to report LPA status"
                    return $OCF_SUCCESS
                fi                             
                promoted=0;
                ;;
            UNDEFINED )
                if ocf_is_probe; then
                   promoted=0;
                else
                   set_hana_attribute ${HOSTNAME} "DEMOTED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
                   promoted=0;
                fi
                ;;
            * )
                promoted=0;
                ;;
        esac
    fi
    get_hana_landscape_status; lss=$? 
    super_ocf_log info "fhDBG saphana_monitor_clone: get_hana_landscape_status=$lss"
    case "$lss" in
        0 | 1 ) # FATAL or ERROR 
            # TODO: PRIO2: Maybe we need to differ between 0 and 1. While 0 is a fatal sap error, 1 is "down/error"
            if ocf_is_probe; then
                # 
                # leave master score untouched, only set return code
                #
                rc=$OCF_NOT_RUNNING
            else
                if [ "$promoted" -eq 1 ]; then
                    # INSTANCE IS FAILED PRIMARY IN PROMOTED STATE
                    # TODO: PRIO2: Adjust with set_crm_master?
                    #       For Migration it would be good to decrease master score
                    #       For Reload locally we should NOT adjust the master score
                    # ===>  Should we rely on the migration threshold?
                    #       set_crm_master 
                    if [ $PreferSiteTakeover -eq 1 ]; then
                        #
                        # TODO: PRIO1: first check, if remote site is already (and still) in sync, so it could at least takeover
                        # TODO: PRIO2: Decide if penality (-9000) or weak (5) is better here to cover situations where other clone is gone
                        #
                        remoteSync=$(get_hana_attribute $remoteHost ${ATTR_NAME_HANA_SYNC_STATUS[@]})
                        case "$remoteSync" in
                            SOK )
                                 super_ocf_log info "fhDEC: PreferSiteTakeover selected so decrease promotion score here (and reset lpa)"
                                 set_crm_master 5
                                 # TODO: PRIO1: CHECK, IF lpa_set_lpt 10 IS CORRECT HERE 
                                 #       - IS IT BETTER TO SET lpa_set_lpt 20?
                                 #       1. lpa_set_lpt 10
                                 #       - Problem is, if BOTH hana sites failed, but remoteSync is still SOK than I get a lpa 10-10 situation
                                 #       2. lpa_set_lpt 20:
                                 #       a) both instances are failing:
                                 #          both clones been restarted coming up with lpa 20-10 -> local wins which is OK
                                 #       b) only former primary failed:
                                 #          former primary restarted and former secondary promoted (sequence not sure!)
                                 #          b1) primary coming up first -> lpa 20-10 -> This would be WRONG!!
                                 #          b2) secondary promted first -> lpa 20-lpt -> former secondary wins which is OK
                                 #       3. lpa_set_lpt UNTUCHED (lpt)
                                 #       a) both instances are failing:
                                 #          both clones been restarted and coming up with lpa lpt-10 -> local wins which is OK
                                 #       b) only former primary failed:
                                 #          former primary restarted and former secondary promoted (sequence not sure!)
                                 #          b1) primary coming up first -> lpa lpt-10 -> This would be WRONG!!
                                 #          b2) secondary promted first -> lpa lpt1-lpt2 -> former primary will wait until gab is closed
                                 #       
                                 # SOLUTION THE VALUE OF 20 HERE NEEDS A "HOT" SECONDARY TO SET VALUE 30 and a "COLD" 10
                                 #
                                 lpa_set_lpt 20
                                 ;;
                            SFAIL )
                                 super_ocf_log info "fhDEC: PreferSiteTakeover selected BUT remoteHost is not in sync (SFAIL) -> local restart preferred"                            
                                 ;;
                            * ) 
                                 super_ocf_log info "fhDEC: PreferSiteTakeover selected BUT remoteHost is not in sync ($remoteSync) -> local restart preferred"                            
                                 ;;
                        esac                        
                    else 
                        # TODO:  PRIO5: SCALE-OUT ONLY? Implement for local restart
                        #        It maybe that for the local restart we only need to decrease the secondaries promotion score
                        #super_ocf_log info "fhDEC: PreferSiteTakeover selected so decrease promotion score here"
#BAUSTELLE1 Primary
    my_role=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_ROLES[@]})
    my_sync=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_SYNC_STATUS[@]})
    scoring_crm_master "$my_role" "$my_sync"
                        rc=$OCF_FAILED_MASTER
                    fi
                    rc=$OCF_FAILED_MASTER
                else
                    # INSTANCE IS FAILED PRIMARY IN DEMOTED STATE
                    # TODO: PRIO3: Adjust with set_crm_master?
                    #       Current decission: Do NOT adjust master score now as other
                    #       steps ahould already have done that
                    #
                    rc=$OCF_NOT_RUNNING
                fi
            fi
            ;;
        2 | 3 | 4 ) # WARN, INFO or OK
            if ocf_is_probe; then
                rc=$OCF_SUCCESS
            else
                #
                #### LPA begin
                #
                # TODO: PRIO2: DO NOT set this lpt, if have started a secondary before!
                #
                LPTloc=$(date '+%s')
                lpa_set_lpt $LPTloc
                lpa_push_lpt $LPTloc
                #
                #### LPA end
                #
                if [ "$promoted" -eq 1 ]; then
                    set_hana_attribute "$HOSTNAME" "PRIM" ${ATTR_NAME_HANA_SYNC_STATUS[@]}
                    rc=$OCF_RUNNING_MASTER
                else
                    if [ "$init_attribute" -eq 1 ]; then
                        set_hana_attribute ${HOSTNAME} "PROMOTED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
                        rc=$OCF_RUNNING_MASTER
                    else
                        rc=$OCF_SUCCESS
                    fi
                fi
#BAUSTELLE1 Primary
    # TODO: PRIO5: SCALE-OUT: Only analyze sync at primary master
    analyze_hana_sync_status
    my_role=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_ROLES[@]})
    my_sync=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_SYNC_STATUS[@]})
    scoring_crm_master "$my_role" "$my_sync"
                #set_crm_master 1000
            fi
            ;;
        * ) # UNDEFINED STATUS
            if ocf_is_probe; then
                rc=$OCF_NOT_RUNNING
            else
                if [ "$promoted" -eq 1 ]; then
                     rc=$OCF_FAILED_MASTER
                else
                     rc=$OCF_NOT_RUNNING
                fi
            fi
            ;;
    esac
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# function: saphana_monitor_secondary - monitor a hana clone instance
# params:   -
# globals:  TBD
# saphana_monitor_secondary
#
function saphana_monitor_secondary()
{
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
	local rc=$OCF_ERR_GENERIC
	local promoted=0
    local init_attribute=0
    local lss
    #
    # OK, we are running as HANA SECONDARY (or even not as PRIMARY)
    #    
    #### LPA begin
    #
    if ! lpa_get_lpt ${HOSTNAME}; then
        lpa_set_lpt  10
        lpa_push_lpt 10
    fi
    #
    #### LPA end
    #
    ##### CHECK, IF WE ARE DEMOTED (CLUSTER NODE ATTRIBUTE)
    #
    promote_attr=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_CLONE_STATE[@]})
    super_ocf_log info "fhDBG saphana_monitor_clone: $ATTR_NAME_HANA_CLONE_STATE=$promote_attr"
    if [ -z "$promote_attr" ]; then
        init_attribute=1
        #  TODO: PRIO3: do we need to inizialize also the DEMOTED attribute value?
        promoted=0;
    else
        case "$promote_attr" in
            PROMOTED ) # However - PROMOTED should never happen for a SECONDARY
                promoted=1;
                ;;
            DEMOTED )  # This is the status we expect
                promoted=0;
                ;;
            WAITING* )  # We are WAITING for PRIMARY so not testing the HANA engine now but check for a new start
                if false; then
                    #
                    # TODO: PRIO1: remove this and maybe replace it by the attribute-check
                    # OLD code based on SQL query
                    #
                    saphana_hdbsql_check remote; sqlrc=$?
                    if [ $sqlrc -eq 0 ]; then
                        super_ocf_log info "fhDBG saphana_monitor_clone: SECONDARY still in status WAITING - Primary now available - try a new start"
                        saphana_start_clone
                        rc=$?
                    else
                        super_ocf_log info "fhDBG saphana_monitor_clone: SECONDARY still in status WAITING - Primary is still missing (sqlrc=$sqlrc)"
                        return $OCF_SUCCESS
                    fi
                else
                    #
                    # NEW code based on cluster attributes
                    #
                    if check_for_primary_master; then
                        super_ocf_log info "fhDBG NEW saphana_monitor_clone: SECONDARY still in status WAITING - Primary now available - try a new start"
                        saphana_start_clone
                        rc=$?
                    else
                        super_ocf_log info "fhDBG NEW saphana_monitor_clone: SECONDARY still in status WAITING - Primary is still missing"
                        return $OCF_SUCCESS
                    fi
                fi
                
                promoted=0;
                ;;
            UNDEFINED )
                if ocf_is_probe; then
                   promoted=0;
                else
                   set_hana_attribute ${HOSTNAME} "DEMOTED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
                   promoted=0;
                fi
                ;;
            * )
                promoted=0;
                ;;
        esac
    fi
    #
    super_ocf_log info "fhDBG saphana_monitor_clone: HANA_STATE_SECONDARY"
    #
    # old method was: saphana_monitor - new method is get_hana_landscape_status
    get_hana_landscape_status; lss=$? 
    super_ocf_log info "fhDBG saphana_monitor_clone: get_hana_landscape_status=$lss"
    case "$lss" in
        0 | 1 ) # FATAL or ERROR
            # TODO: PRIO1: Maybe we need to differ between 0 and 1. While 0 is a fatal sap error, 1 is "down/error"
            lpa_set_lpt  10
            rc=$OCF_NOT_RUNNING
            ;;
        2 | 3 | 4 ) # WARN INFO OK
            rc=$OCF_SUCCESS
            lpa_set_lpt  30
            sync_attr=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_SYNC_STATUS[@]})
            super_ocf_log info "fhDBG sync_attr=$sync_attr"
            case "$sync_attr" in
                "SOK"   )    # This is a possible node to promote, when primary is missing
                    super_ocf_log info "fhDEC: secondary with sync status SOK -> posible takeover node"
                #    set_crm_master  10
#BAUSTELLE1 Secondary
    my_role=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_ROLES[@]})
    my_sync=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_SYNC_STATUS[@]})
    scoring_crm_master "$my_role" "$my_sync"
                    ;;
                "SFAIL" ) # This is currently NOT a possible node to promote
                    super_ocf_log info "fhDEC: secondary with sync status FAILED -> EXCLUDE as posible takeover node"
                    set_crm_master -INFINITY
                    ;;
                "*" )       # Unknown sync status
                    super_ocf_log info "fhDEC: secondary with sync status UKNOWN/UNDEFINED -> EXCLUDE as posible takeover node"
                    set_crm_master -INFINITY
                    ;;
            esac
            ;;
        * ) # UNDEFINED STATUS
            rc=$OCF_NOT_RUNNING
            ;;
    esac
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# function: saphana_monitor_clone - monitor a hana clone instance
# params:   -
# globals:  TBD
# saphana_monitor_clone
#
function saphana_monitor_clone() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    #
    # TODO: PRIO1: For the secondary, which is missing the primary (so in status WAITING) what is better:
    #       a) returning 7 here and force cluster a restart of the slave
    #       b) starting the instance here inside the monitor -> may result in longer runtime, timeouts
    #
	# first check with the status function (OS tools) if there could be something like a SAP instance running
	# as we do not know here, if we are in master or slave state we do not want to start our monitoring
	# agents (sapstartsrv) on the wrong host
	local rc=$OCF_ERR_GENERIC
	local promoted=0
    local init_attribute=0


# BAUSTELLE1 : Vermutlch wieder hier raus tun ;-)
    my_role=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_ROLES[@]})
    my_sync=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_SYNC_STATUS[@]})
    #scoring_crm_master "$my_role" "$my_sync"

    lpa_check_lpt_status  # TODO: PRIO3 : remove that line later - its only to call lpa_check_lpt_status much more often for checking

	if ocf_is_probe; then
		super_ocf_log info "fhDBG: PROBE ONLY"
	else
		super_ocf_log info "fhDBG: REGULAR MONITOR"
	fi
	#
	# First check, if we are PRIMARY or SECONDARY
	# 
	check_for_primary; primary_status=$?
    if [ $primary_status -eq $HANA_STATE_PRIMARY ]; then
        saphana_monitor_primary; rc=$?
    else
        if [ $primary_status -eq $HANA_STATE_SECONDARY  ]; then
            saphana_monitor_secondary; rc=$?
        else
            #
            # OK, we are neither HANA PRIMARY nor HANA SECONDARY
            #
            super_ocf_log info "fhDBG saphana_monitor_clone: HANA_STATE_DEFECT"
            # TODO: PRIO2: Or only set_crm_master -INFINITY ?
            rc=$OCF_ERR_GENERIC
        fi
    fi
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# function: saphana_promote_clone - promote a hana clone
# params:   -
# globals:  OCF_*(r), HOSTNAME(r), HANA_STATE_*, SID(r), InstanceName(r), 
# saphana_promote_clone: 
#    In a Master/Slave configuration get Master being the primary OR by running hana takeover
#
function saphana_promote_clone() {
  super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
  local rc=$OCF_ERR_GENERIC;
  local hana_sync;
  local primary_status;
  #
  # first check, if we WILL be PRIMARY (checking HANA status)
  #
  check_for_primary; primary_status=$?
  #
  if [ $primary_status -eq $HANA_STATE_PRIMARY ]; then
     #
     # as we are already planned to be PRIMARY we only mark the node as PROMOTED
     #
     set_hana_attribute ${HOSTNAME} "PROMOTED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
     rc=$OCF_SUCCESS;
     super_ocf_log info "fhACT: Promoted $SID-$InstanceName as master (no hdbnsutil action needed)."
  else
     if [ $primary_status -eq $HANA_STATE_SECONDARY ]; then
        #
        # we are SECONDARY/SLAVE and need to takepover ...
        # promote on the replica side...
        #
        hana_sync=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_SYNC_STATUS[@]})
        case "$hana_sync" in
             SOK )
                super_ocf_log info "fhACT: !!!!!!! Promote REPLICA $SID-$InstanceName to be primary. !!!!!!"
                su - $sidadm -c "hdbnsutil -sr_takeover"
                #
                # now gain check, if we are primary NOW
                #
                # TODO: PRIO3: check, if we need to destigush between HANA_STATE_PRIMARY, HANA_STATE_SECONDARY, HANA_STATE_DEFECT
                #
                if check_for_primary; then
                    set_hana_attribute ${HOSTNAME} "PROMOTED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
                    rc=$OCF_SUCCESS;
                else
                    set_hana_attribute ${HOSTNAME} "PROMOTED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
                    rc=$OCF_FAILED_MASTER
                fi 
                ;;
             * )
                super_ocf_log err "fhACT: !!!!!!! HANA SYNC STATUS IS NOT 'SOK' SO WE COULD NOT PROMOTE !!!!!!!"
                rc=$OCF_ERR_GENERIC
                ;;
        esac
     else
        #
        # neither MASTER nor SLAVE - This clone instance seams to be broken!!
        #
        rc=$OCF_ERR_GENERIC
     fi
  fi
  rc=$?
  super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
  return $rc
}

#
# function: saphana_demote_clone - demote a hana clone instance
# params:   -
# globals:  OCF_*(r), HOSTNAME(r), 
# saphana_demote_clone
#   the HANA System Replication (SR) runs in a Master/Slave 
#   While we could not change a HANA instance to be really demoted, we only mark the status for 
#   correct monitor return codes
#
function saphana_demote_clone() {
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local rc=$OCF_ERR_GENERIC;
    set_hana_attribute ${HOSTNAME} "DEMOTED" ${ATTR_NAME_HANA_CLONE_STATE[@]}
    rc=$OCF_SUCCESS;
    super_ocf_log info "fhACT Demoted $SID-$InstanceName."
    super_ocf_log info "fhFLOW $FUNCNAME  -> return code = $rc"
    return $rc
}

#
# function: saphana_notify - notify action
# params:   -
# globals:  OCF_*(r), ACTION(r), CLACT(r), HOSTNAME(r)
# saphana_notify: Handle master scoring - to make sure a slave gets the next master
#
function saphana_notify() {
    super_ocf_log info "fhRA ==== begin action $ACTION$CLACT (${n_type}/${n_op})===="
    super_ocf_log info "fhFLOW function: $FUNCNAME $1 $2 $3 $4"
    local promote_attr
    local rc=0
    #
    # related to notification
    #
    local n_type="$OCF_RESKEY_CRM_meta_notify_type"
    local n_op="$OCF_RESKEY_CRM_meta_notify_operation"
    #
    # related to resources
    #
    local n_act="$OCF_RESKEY_CRM_meta_notify_active_resource"
    local n_iact="$OCF_RESKEY_CRM_meta_notify_inactive_resource"
    local n_master="$OCF_RESKEY_CRM_meta_notify_master_resource"
    local n_slave="$OCF_RESKEY_CRM_meta_notify_slave_resource"
    local n_start="$OCF_RESKEY_CRM_meta_notify_start_resource"
    local n_stop="$OCF_RESKEY_CRM_meta_notify_stop_resource"
    local n_promote="$OCF_RESKEY_CRM_meta_notify_promote_resource"
    local n_demote="$OCF_RESKEY_CRM_meta_notify_demote_resource"
    #
    # related to nodes
    #
    local n_startU="$OCF_RESKEY_CRM_meta_notify_start_uname"
    local n_stopU="$OCF_RESKEY_CRM_meta_notify_stop_uname"
    local n_promoteU="$OCF_RESKEY_CRM_meta_notify_promote_uname"
    local n_demoteU="$OCF_RESKEY_CRM_meta_notify_demote_uname"
    local n_actU="$OCF_RESKEY_CRM_meta_notify_active_uname"
    local n_iactU="$OCF_RESKEY_CRM_meta_notify_inactive_uname"
    local n_masterU="$OCF_RESKEY_CRM_meta_notify_master_uname"
    local n_slaveU="$OCF_RESKEY_CRM_meta_notify_slave_uname"

    saphana_notify_log_values "n_act/n_iact" "${n_act}/${n_iact}"
    saphana_notify_log_values "n_master/n_slave" "${n_master}/${n_slave}"
    saphana_notify_log_values "n_start/n_stop" "${n_start}/${n_stop}"
    saphana_notify_log_values "n_promote/n_demote" "${n_promote}/${n_demote}"
    saphana_notify_log_values "n_startU/n_stopU" "${n_startU}/${n_stopU}"
    saphana_notify_log_values "n_promoteU/n_demoteU" "${n_promoteU}/${n_demoteU}"
    saphana_notify_log_values "n_actU/n_iactU" "${n_actU}/${n_iactU}"
    saphana_notify_log_values "n_masterU/n_slaveU" "${n_masterU}/${n_slaveU}"
    case "${n_type}_${n_op}" in
        post_promote )
            # WORKING-ZONE
            promote_attr=$(get_hana_attribute ${HOSTNAME} ${ATTR_NAME_HANA_CLONE_STATE[@]})
		    case "$promote_attr" in
                WAITING )  
                    ;;
            esac
            ;;
    esac
    super_ocf_log info "fhRA ==== end action $ACTION$CLACT (${n_type}/${n_op})===="
    return $rc
}

#
# function: main - main function to operate 
# params:   ACTION
# globals:  OCF_*(r), SID(w), sidadm(w), InstanceName(w), SAPVIRHOST(w), DIR_EXECUTABLE(w), 
# globals:  SAPSTARTSRV(w), SAPCONTROL(w), DIR_PROFILE(w), SAPSTARTPROFILE(w), ACTION(w), CLACT(w), ra_rc(rw), $0(r), %ENV(r)
#

## GLOBALS
SID=""
sidadm=""
InstanceName=""
InstanceNr=""
SAPVIRHOST=""
DIR_EXECUTABLE=""
SAPSTARTSRV=""
SAPCONTROL=""
DIR_PROFILE=""
SAPSTARTPROFILE=""
SAPHanaFilter="${OCF_RESKEY_SAPHanaFilter:-all}"


if [ $# -ne 1 ]
then
  saphana_usage
  exit $OCF_ERR_ARGS
fi

ACTION=$1
if [ "$ACTION" = "status" ]; then
    ACTION=monitor
fi

# These operations don't require OCF parameters to be set
# TODO: PRIO5: check, if notify is still not needing OCF parameters
case "$ACTION" in
    usage|methods)  saphana_$ACTION
                    exit $OCF_SUCCESS;;
    meta-data)      saphana_meta_data
                    exit $OCF_SUCCESS;;
    notify)         saphana_notify
                    exit $OCF_SUCCESS;;
    *);;
esac
saphana_init 

if ! ocf_is_root
then
    super_ocf_log err "$0 must be run as root"
    exit $OCF_ERR_PERM
fi

# parameter check
if  [ -z "$OCF_RESKEY_SID" ]
then
    super_ocf_log err "Please set OCF_RESKEY_SID!"
    exit $OCF_ERR_ARGS
fi

if  [ -z "$OCF_RESKEY_InstanceNumber" ]
then
    super_ocf_log err "Please set OCF_RESKEY_InstanceNumber!"
    exit $OCF_ERR_ARGS
fi

if is_clone
then
    CLACT=_clone
else
    if [ "$ACTION" = "promote" -o "$ACTION" = "demote" ]
    then
        super_ocf_log err "$ACTION called in a non master/slave environment"
        exit $OCF_ERR_ARGS
    fi
fi

# What kind of method was invoked?
THE_VERSION=$(saphana_meta_data | grep '<version')
super_ocf_log info "fhRA ==== begin action $ACTION$CLACT ($THE_VERSION) ===="
ra_rc=$OCF_ERR_UNIMPLEMENTED
case "$ACTION" in
    start|stop|monitor|promote|demote) # Standard controling actions
        saphana_$ACTION$CLACT
        ra_rc=$?
        ;;
    validate-all) 
        saphana_validate
        ra_rc=$?
        ;;
    lpa_check)
        lpa_check_lpt_status
        ra_rc=$?
        ;;
    *)  # seams to be a unknown request 
        saphana_methods 
        ra_rc=$OCF_ERR_UNIMPLEMENTED
        ;;
esac
timeE=$(date '+%s')
(( timeR = timeE - timeB ))
super_ocf_log info "fhRA ==== end action $ACTION$CLACT with rc=${ra_rc} ($THE_VERSION) (${timeR}s)===="
exit ${ra_rc}
