#!/bin/sh
#
# SAPInstance
#
# Description:	Manages a single SAP Instance as a High-Availability
#		resource. One SAP Instance is defined by one 
#               SAP Instance-Profile. start/stop handels all services
#               of the START-Profile, status and monitor care only
#               about essential services.
#
##################################################################################################################################################
#
# A fork of SAPInstance to cover special actions needed for running HANA in a SR mode
#
# SAPHana:
# Author:       Fabian Herschel, 2013
# Support:      linux@sap.com
# License:      GNU General Public License (GPL)
# Copyright:    (c) 2013 SUSE Linux Products GmbH

# SAPInstance:
# Author:       Alexander Krauth, June 2006
# Support:      linux@sap.com
# License:      GNU General Public License (GPL)
# Copyright:    (c) 2006-2008 Alexander Krauth
#
# An example usage: 
#      See usage() function below for more details...
#
# OCF instance parameters:
#yes:	OCF_RESKEY_InstanceName
#yes:	OCF_RESKEY_DIR_EXECUTABLE   (optional, well known directories will be searched by default)
#yes:	OCF_RESKEY_DIR_PROFILE      (optional, well known directories will be searched by default)
#yes:	OCF_RESKEY_PROFILE          (optional, well known directories will be searched by default)
#yes:   OCF_RESKEY_PREFER_SITE_TAKEOVER (optional, default is no)
#chk:	OCF_RESKEY_START_WAITTIME   (optional, to solve timing problems during J2EE-Addin start)
#chk:	OCF_RESKEY_AUTOMATIC_RECOVER    (optional, automatic startup recovery using cleanipc, default is false)
#       OCF_RESKEY_MONITOR_SERVICES     (optional, default is to monitor critical services only)
#       OCF_RESKEY_SHUTDOWN_METHOD      (optional, defaults to NORMAL, KILL: terminate the SAP instance with OS commands - faster, at your own risk)
#no:       OCF_RESKEY_ERS_InstanceName     (optional, InstanceName of the ERS instance in a Master/Slave configuration)
#no:       OCF_RESKEY_ERS_START_PROFILE    (optional, START_PROFILE of the ERS instance in a Master/Slave configuration)
#	OCF_RESKEY_PRE_START_USEREXIT	(optional, lists a script which can be executed before the resource is started)
#	OCF_RESKEY_POST_START_USEREXIT	(optional, lists a script which can be executed after the resource is started)
#	OCF_RESKEY_PRE_STOP_USEREXIT	(optional, lists a script which can be executed before the resource is stopped)
#	OCF_RESKEY_POST_STOP_USEREXIT	(optional, lists a script which can be executed after the resource is stopped)
#
#  TODO: - Option to shutdown sapstartsrv for non-active instances -> that means: do probes only with OS tools (saphana_status)
#        - Option for better standalone enqueue server monitoring, using ensmon (test enque-deque)
#        - Option for cleanup abandoned enqueue replication tables
#
#######################################################################
# Initialization:

: ${OCF_FUNCTIONS_DIR=${OCF_ROOT}/lib/heartbeat}
. ${OCF_FUNCTIONS_DIR}/ocf-shellfuncs

#######################################################################

HANA_STATE_PRIMARY=0
HANA_STATE_SECONDARY=1
HANA_STATE_DEFECT=2

SH=/bin/sh

saphana_usage() {
  methods=`saphana_methods`
  methods=`echo $methods | tr ' ' '|'`
  cat <<-!
	usage: $0 ($methods)

	$0 manages a SAP Instance as an HA resource.

	The 'start' operation starts the instance or the ERS instance in a Master/Slave configuration
	The 'stop' operation stops the instance
	The 'status' operation reports whether the instance is running
	The 'monitor' operation reports whether the instance seems to be working
        The 'promote' operation starts the primary instance in a Master/Slave configuration
        The 'demote' operation stops the primary instance and starts the ERS instance
        The 'notify' operation always returns SUCCESS
	The 'validate-all' operation reports whether the parameters are valid
	The 'methods' operation reports on the methods $0 supports

	!
}

saphana_meta_data() {
	cat <<END
<?xml version="1.0"?>
<!DOCTYPE resource-agent SYSTEM "ra-api-1.dtd">
<resource-agent name="SAPInstance">
<version>0.10</version>

<shortdesc lang="en">Manages a SAP HANA instance.</shortdesc>
<longdesc lang="en">
TBD

1. Interface
sapstartsrv knows 4 status colours:
- GREEN   = everything is fine
- YELLOW  = something is wrong, but the service is still working
- RED     = the service does not work
- GRAY    = the service has not been started
The SAPInstance resource agent will interpret GREEN and YELLOW as OK. That means that minor problems will not be reported to the Heartbeat cluster. This prevents the cluster from doing an unwanted failover.
The statuses RED and GRAY are reported as NOT_RUNNING to the cluster. Depending on the status the cluster expects from the resource, it will do a restart, failover or just nothing.

2. Interface:
returncode of script ...

0: Internal Fatal
1: ERROR
2: WARNING
3: INFO (maybe a switch of the resource running)
4: OK

</longdesc>
<parameters>
 <parameter name="InstanceName" unique="1" required="1">
  <longdesc lang="en">The full qualified SAP instance name. e.g. P01_DVEBMGS00_sapp01ci. Usually this is the name of the SAP instance profile.</longdesc>
  <shortdesc lang="en">Instance name: SID_INSTANCE</shortdesc>
  <content type="string" default="" />
 </parameter>
 <parameter name="PREFER_SITE_TAKEOVER" unique="0" required="0">
 <longdesc lang="en">Should cluster/RA prefer to switchover to slave instance instead of restarting master locally? Default=No</longdesc>
 <shortdesc lang="en">Local or site recover preferred?</shortdesc>
  <content type="boolean" default="0" />
 </paramater>
 <parameter name="DIR_EXECUTABLE" unique="0" required="0">
  <longdesc lang="en">The full qualified path where to find sapstartsrv and sapcontrol. Specify this parameter, if you have changed the SAP kernel directory location after the default SAP installation.</longdesc>
  <shortdesc lang="en">Path of sapstartsrv and sapcontrol</shortdesc>
  <content type="string" default="" />
 </parameter>
 <parameter name="DIR_PROFILE" unique="0" required="0">
  <longdesc lang="en">The full qualified path where to find the SAP START profile. Specify this parameter, if you have changed the SAP profile directory location after the default SAP installation.</longdesc>
  <shortdesc lang="en">Path of start profile</shortdesc>
  <content type="string" default="" />
 </parameter>
 <parameter name="PROFILE" unique="1" required="0">
  <longdesc lang="en">The name of the SAP START profile. Specify this parameter, if you have changed the name of the SAP START profile after the default SAP installation. As SAP release 7.10 does not have a START profile anymore, you need to specify the Instance Profile than.</longdesc>
  <shortdesc lang="en">HANA instance profile name</shortdesc>
  <content type="string" default="" />
 </parameter>
 <parameter name="START_WAITTIME" unique="0" required="0">
  <longdesc lang="en">After that time in seconds a monitor operation is executed by the resource agent. Does the monitor return SUCCESS, the start ishandled as SUCCESS. This is useful to resolve timing problems with e.g. the J2EE-Addin instance.Usually the resource agent waits until all services are started and the SAP Management Console reports a GREEN status. A double stack installation (ABAP + Java AddIn) consists of an ABAP dispatcher and aJAVA instance. Normally the start of the JAVA instance takes much longer than the start of the ABAP instance. For a JAVA Instance you may need to configure a much higher timeout for the start operation of the resource in Heartbeat. The disadvantage here is, that the discovery of a failed start by the cluster takes longer. Somebody might say: For me it is important, that the ABAP instance is up and running. A failure of the JAVA instance shall not cause a failover of the SAP instance.
Actually the SAP MC reports a YELLOW status, if the JAVA instance of a double stack system fails. From the resource agent point of view YELLOW means:everything is OK. Setting START_WAITTIME to a lower value determines the resource agent to check the status of the instance during a start operation after that time. As it would wait normally for a GREEN status, now it reports SUCCESS to the cluster in case of a YELLOW status already after the specified time.

That is only useful for double stack systems.
  </longdesc>
  <shortdesc lang="en">Check the successful start after that time (do not wait for J2EE-Addin)</shortdesc>
  <content type="string" default="3600" />
 </parameter>
 <parameter name="AUTOMATIC_RECOVER" unique="0" required="0">
  <longdesc lang="en">The SAPInstance resource agent tries to recover a failed start attempt automaticaly one time. This is done by killing runing instance processes, removing the kill.sap file and executing cleanipc. Sometimes a crashed SAP instance leaves some processes and/or shared memory segments behind. Setting this option to true will try to remove those leftovers during a start operation. That is to reduce manual work for the administrator.</longdesc>
  <shortdesc lang="en">Enable or disable automatic startup recovery</shortdesc>
  <content type="boolean" default="false"/>
 </parameter>
 <parameter name="MONITOR_SERVICES" unique="0" required="0">
  <longdesc lang="en">Within a SAP instance there can be several services. Usually you will find the defined services in the START profile of the related instance (Attention: with SAP Release 7.10 the START profile content was moved to the instance profile). Not all of those services are worth to monitor by the cluster. For example you properly do not like to failover your SAP instance, if the central syslog collector daemon fails.
Those services are monitored within the SAPInstance resource agent:

- disp+work
- msg_server
- enserver
- enrepserver
- jcontrol
- jstart

That names match the strings used in the output of the command 'sapcontrol -nr [Instance-Nr] -function GetProcessList'.
The default should fit most cases where you want to manage a SAP Instance from the cluster. You may change this with this parameter, if you like to monitor more/less or other services that sapstartsrv supports.
You may specify multiple services seperated by a | (pipe) sign in this parameter: disp+work|msg_server|enserver
  </longdesc>
  <shortdesc lang="en">Services to monitor</shortdesc>
  <content type="string" default="disp+work|msg_server|enserver|enrepserver|jcontrol|jstart"/>
 </parameter>
  <parameter name="SHUTDOWN_METHOD" unique="0" required="0">
  <longdesc lang="en">Usual a SAP Instance is stopped by the command 'sapcontrol -nr InstanceNr -function Stop'. SHUTDOWN_METHOD=KILL means to kill the SAP Instance using OS commands. SAP processes of the instance are terminated with 'kill -9', shared memory is deleted with 'cleanipc' and the 'kill.sap' file will be deleted. That method is much faster than the gracefull stop, but the instance does not have the chance to say goodbye to other SAPinstances in the same system. USE AT YOUR OWN RISK !!</longdesc>
  <shortdesc lang="en">Shutdown graceful or kill a SAP instance by terminating the processes. (normal|KILL)</shortdesc>
  <content type="string" default="normal"/>
 </parameter>
 <parameter name="PRE_START_USEREXIT" unique="0" required="0">
  <longdesc lang="en">The full qualified path where to find a script or program which should be executed before this resource gets started.</longdesc>
  <shortdesc lang="en">Path to a pre-start script</shortdesc>
  <content type="string" default="" />
 </parameter>
 <parameter name="POST_START_USEREXIT" unique="0" required="0">
  <longdesc lang="en">The full qualified path where to find a script or program which should be executed after this resource got started.</longdesc>
  <shortdesc lang="en">Path to a post-start script</shortdesc>
  <content type="string" default="" />
 </parameter>
 <parameter name="PRE_STOP_USEREXIT" unique="0" required="0">
  <longdesc lang="en">The full qualified path where to find a script or program which should be executed before this resource gets stopped.</longdesc>
  <shortdesc lang="en">Path to a pre-start script</shortdesc>
  <content type="string" default="" />
 </parameter>
 <parameter name="POST_STOP_USEREXIT" unique="0" required="0">
  <longdesc lang="en">The full qualified path where to find a script or program which should be executed after this resource got stopped.</longdesc>
  <shortdesc lang="en">Path to a post-start script</shortdesc>
  <content type="string" default="" />
 </parameter>
</parameters>

<actions>
<action name="start" timeout="180" />
<action name="stop" timeout="240" />
<action name="status" timeout="60" />
<action name="monitor" depth="0" timeout="60" interval="120" />
<action name="monitor" depth="0" timeout="60" interval="121" role="Slave" />
<action name="monitor" depth="0" timeout="60" interval="119" role="Master" />
<action name="promote" timeout="320" />
<action name="demote" timeout="320" />
<action name="validate-all" timeout="5" />
<action name="meta-data" timeout="5" />
<action name="methods" timeout="5" />
</actions>
</resource-agent>
END
}


#
# methods: What methods/operations do we support?
#
saphana_methods() {
  cat <<-!
	start
	stop
	status
	monitor
        promote
        demote
        notify
	validate-all
	methods
	meta-data
	usage
	!
}


dequote()
{
   tr -d '"'
}

#
# is_clone : find out if we are configured to run in a Master/Slave configuration
#
is_clone() {
  local rc=0
  if [ -n "$OCF_RESKEY_CRM_meta_clone_max" ] \
   && [ "$OCF_RESKEY_CRM_meta_clone_max" -gt 0 ]
  then
#    if [ "$OCF_RESKEY_CRM_meta_clone_max" -ne 2 ] || \
#       [ "$OCF_RESKEY_CRM_meta_clone_node_max" -ne 1 ] || \
#       [ "$OCF_RESKEY_CRM_meta_master_node_max" -ne 1 ] || \
#       [ "$OCF_RESKEY_CRM_meta_master_max" -ne 1 ]
#    then
#            ocf_log err "Clone options misconfigured. (expect: clone_max=2,clone_node_max=1,master_node_max=1,master_max=1)"
#            exit $OCF_ERR_CONFIGURED
#    fi
    rc=0;
  else
    rc=1;
  fi
  return $rc
}


#
# TODO: fh - check, if we will follow this concept also for HANA installations
# abnormal_end : essential things are missing, but in the natur of a SAP installation - which can be very different
#                from customer to customer - we cannot handle this always as an error
#                This would be the case, if the software is installed on shared disks and not visible
#                to all cluster nodes at all times.
#
abnormal_end() {
  local err_msg=$1

  ocf_is_probe && {
    saphana_status
    exit $?
  }

  if [ "$ACTION" = "stop" ]
  then
    cleanup_instance
    exit $OCF_SUCCESS
  fi

  ocf_log err $err_msg
  exit $OCF_ERR_CONFIGURED
}


set_crm_master()
{
   local score=0
   if [ -n "$1" ]; then
      score=$1
   fi
   ${HA_SBIN_DIR}/crm_master -v $score -l reboot
   logger -t fhLOG "crm_master with: $OCF_RESOURCE_INSTANCE -v $score -l reboot"
}

get_crm_master()
{
   ${HA_SBIN_DIR}/crm_master -G -q -l reboot
}

#
# saphana_init : Define global variables with default values, if optional parameters are not set
#
#
saphana_init() {

  local myInstanceName="$1"

  SID=$(echo "$myInstanceName" | cut -d_ -f1)
  sid=$(echo "$SID" | tr [:upper:] [:lower:])
  sidadm="${sid}adm"
  InstanceName=$(echo "$myInstanceName" | cut -d_ -f2)
  SIDInstanceName=${myInstanceName}
  InstanceNr=$(echo "$InstanceName" | sed 's/.*\([0-9][0-9]\)$/\1/')
  #SAPVIRHOST=$(echo "$myInstanceName" | cut -d_ -f3)
  SAPVIRHOST=$(hostname)
  PreferSiteTakeover="$OCF_RESKEY_PREFER_SITE_TAKEOVER"
  meta_notify_master_uname="$OCF_RESKEY_CRM_meta_notify_master_uname"

  ocf_log info "fhDBG: SID=$SID, sid=$sid, SIDInstanceName=$SIDInstanceName, InstanceName=$InstanceName, InstanceNr=$InstanceNr, SAPVIRHOST=$SAPVIRHOST meta_notify_master_uname=$meta_notify_master_uname"

  ocf_env=$(env | grep 'OCF_RESKEY_CRM')
  ocf_log info "fhDBG: OCF: $ocf_env"
   
  ATTR_NAME_HANA_SYNC_STATUS="hana_${sid}_sync_state"
  ATTR_NAME_HANA_PRIMARY_AT="hana_${sid}_primary_at"
  ATTR_NAME_HANA_CLONE_STATE="hana_${sid}_clone_state"

  # optional OCF parameters, we try to guess which directories are correct
  if  [ -z "$OCF_RESKEY_DIR_EXECUTABLE" ]
  then
    if have_binary /usr/sap/$SID/$InstanceName/exe/sapstartsrv && have_binary /usr/sap/$SID/$InstanceName/exe/sapcontrol
    then
      DIR_EXECUTABLE="/usr/sap/$SID/$InstanceName/exe"
      SAPSTARTSRV="/usr/sap/$SID/$InstanceName/exe/sapstartsrv"
      SAPCONTROL="/usr/sap/$SID/$InstanceName/exe/sapcontrol"
    elif have_binary /usr/sap/$SID/SYS/exe/run/sapstartsrv && have_binary /usr/sap/$SID/SYS/exe/run/sapcontrol
    then
      DIR_EXECUTABLE="/usr/sap/$SID/SYS/exe/run"
      SAPSTARTSRV="/usr/sap/$SID/SYS/exe/run/sapstartsrv"
      SAPCONTROL="/usr/sap/$SID/SYS/exe/run/sapcontrol"
    fi
  else
    if have_binary "$OCF_RESKEY_DIR_EXECUTABLE/sapstartsrv" && have_binary "$OCF_RESKEY_DIR_EXECUTABLE/sapcontrol"
    then
      DIR_EXECUTABLE="$OCF_RESKEY_DIR_EXECUTABLE"
      SAPSTARTSRV="$OCF_RESKEY_DIR_EXECUTABLE/sapstartsrv"
      SAPCONTROL="$OCF_RESKEY_DIR_EXECUTABLE/sapcontrol"
    fi
  fi


  [ -z "$DIR_EXECUTABLE" ] && abnormal_end "Cannot find sapstartsrv and sapcontrol executable, please set DIR_EXECUTABLE parameter!"

  if [ -z "$OCF_RESKEY_DIR_PROFILE" ]
  then
    DIR_PROFILE="/usr/sap/$SID/SYS/profile"
  else
    DIR_PROFILE="$OCF_RESKEY_DIR_PROFILE"
  fi

  if [ -z "${OCF_RESKEY_PROFILE}" ]
  then
    SAPSTARTPROFILE="$DIR_PROFILE/${SIDInstanceName}_${SAPVIRHOST}"
  else
# TODO: if OCF_RESKEY_PROFILE contains slahes ignore DIR_PROFILE
    SAPSTARTPROFILE="$DIR_PROFILE/${OCF_RESKEY_PROFILE}"
  fi

  if [ -z "$OCF_RESKEY_START_WAITTIME" ]
  then
    export OCF_RESKEY_START_WAITTIME=3600
  fi

  if [ -z "$OCF_RESKEY_MONITOR_SERVICES" ]
  then
# TODO: fh - which HANA service to monitor and are there several kinds of HANA instances with a different needed services set (scale-out)?
    export OCF_RESKEY_MONITOR_SERVICES="hdbindexserver|hdbdaemon"
  fi

  # as root user we need the library path to the SAP kernel to be able to call sapcontrol
  # check, if we already added DIR_EXECUTABLE at the beginning of LD_LIBRARY_PATH
  if [ "${LD_LIBRARY_PATH%%*:}" != "$DIR_EXECUTABLE" ]
  then
    LD_LIBRARY_PATH=$DIR_EXECUTABLE${LD_LIBRARY_PATH:+:}$LD_LIBRARY_PATH
    export LD_LIBRARY_PATH
  fi

  PATH=${PATH}:${DIR_EXECUTABLE}
  # ocf_log info "fhDBG: LD_LIBRARY_PATH=${LD_LIBRARY_PATH}, DIR_EXECUTABLE=${DIR_EXECUTABLE} PATH=${PATH}"
  return $OCF_SUCCESS
}


#
# check_sapstartsrv : Before using sapcontrol we make sure that the sapstartsrv is running for the correct instance.
#                     We cannot use sapinit and the /usr/sap/sapservices file in case of an enquerep instance,
#                     because then we have two instances with the same instance number.
#
check_sapstartsrv() {
  local restart=0
  local runninginst=""
  local chkrc=$OCF_SUCCESS
  local output=""

  if [ ! -S /tmp/.sapstream5${InstanceNr}13 ]; then
    ocf_log warn "sapstartsrv is not running for instance $SID-$InstanceName (no UDS), it will be started now"
    restart=1
  else
    output=`$SAPCONTROL -nr $InstanceNr -function ParameterValue INSTANCE_NAME -format script`
    if [ $? -eq 0 ]
    then
      runninginst=`echo "$output" | grep '^0 : ' | cut -d' ' -f3`
      if [ "$runninginst" != "$InstanceName" ]
      then 
        ocf_log warn "sapstartsrv is running for instance $runninginst, that service will be killed"
        restart=1
      else
        output=`$SAPCONTROL -nr $InstanceNr -function AccessCheck Start`
        if [ $? -ne 0 ]; then
          ocf_log warn "FAILED : sapcontrol -nr $InstanceNr -function AccessCheck Start (`ls -ld1 /tmp/.sapstream5${InstanceNr}13`)"
          ocf_log warn "sapstartsrv will be restarted to try to solve this situation, otherwise please check sapstsartsrv setup (SAP Note 927637)"
          restart=1
        fi
      fi
    else
      ocf_log warn "sapstartsrv is not running for instance $SID-$InstanceName, it will be started now"
      restart=1
    fi
  fi

  if [ -z "$runninginst" ]; then runninginst=$InstanceName; fi

  if [ $restart -eq 1 ]
  then

    if [ -d /usr/sap/$SID/SYS/profile/ ]
    then
      DIR_PROFILE="/usr/sap/$SID/SYS/profile"
    else
      abnormal_end "Expected /usr/sap/$SID/SYS/profile/ to be a directory, please set DIR_PROFILE parameter!"
    fi

    [ ! -r $SAPSTARTPROFILE ] && abnormal_end "Expected $SAPSTARTPROFILE to be the instance START profile, please set START_PROFILE parameter!"

    pkill -9 -f "sapstartsrv.*$runninginst"

    # removing the unix domain socket files as they might have wrong permissions
    # or ownership - they will be recreated by sapstartsrv during next start
    rm -f /tmp/.sapstream5${InstanceNr}13
    rm -f /tmp/.sapstream5${InstanceNr}14

    $SAPSTARTSRV pf=$SAPSTARTPROFILE -D -u $sidadm

    # now make sure the daemon has been started and is able to respond
    local srvrc=1
    while [ $srvrc -eq 1 -a `pgrep -f "sapstartsrv.*$runninginst" | wc -l` -gt 0 ]
    do
      sleep 1
      $SAPCONTROL -nr $InstanceNr -function GetProcessList > /dev/null 2>&1
      srvrc=$?
    done

    if [ $srvrc -ne 1 ]
    then
      ocf_log info "sapstartsrv for instance $SID-$InstanceName was restarted !"
      chkrc=$OCF_SUCCESS
    else
      ocf_log error "sapstartsrv for instance $SID-$InstanceName could not be started!"
      chkrc=$OCF_ERR_GENERIC
      ocf_is_probe && chkrc=$OCF_NOT_RUNNING
    fi
  fi

  return $chkrc
}


#
# sapuserexit : Many SAP customers need some additional processes/tools to run their SAP systems.
#               This specialties do not allow a totally generic SAP cluster resource agent.
#               Someone should write a resource agent for each additional process you need, if it
#               is required to monitor that process within the cluster manager. To enable 
#               you to extent this resource agent without developing a new one, this user exit
#               was introduced.
#
sapuserexit() {
  local NAME="$1"
  local VALUE="$2"

  if [ -n "$VALUE" ]
  then
    if have_binary "$VALUE"
    then
      ocf_log info "Calling userexit ${NAME} with customer script file ${VALUE}"
      "$VALUE" >/dev/null 2>&1
      ocf_log info "Exiting userexit ${NAME} with customer script file ${VALUE}, returncode: $?"
    else
      ocf_log warn "Attribute ${NAME} is set to ${VALUE}, but this file is not executable"
    fi
  fi
  return 0
}


#
# cleanup_instance : remove resources (processes and shared memory) from a crashed instance)
#
cleanup_instance() {
# TODO: fh - Do not know what we need for HANA cleanup
  pkill -9 -f -U $sidadm $InstanceName
  ocf_log info "Terminated instance using 'pkill -9 -f -U $sidadm $InstanceName'"

  # it is necessary to call cleanipc as user sidadm if the system has 'vmcj/enable = ON' set - otherwise SHM-segments in /dev/shm/SAP_ES2* cannot beremoved
  su - $sidadm -c "cleanipc $InstanceNr remove"
  ocf_log info "Tried to remove shared memory resources using 'cleanipc $InstanceNr remove' as user $sidadm"

  ocf_run rm -fv /usr/sap/$SID/$InstanceName/work/kill.sap
  ocf_run rm -fv /usr/sap/$SID/$InstanceName/work/shutdown.sap
  ocf_run rm -fv /usr/sap/$SID/$InstanceName/data/rslgcpid
  ocf_run rm -fv /usr/sap/$SID/$InstanceName/data/rslgspid

  return 0
}

#
# saphana_start : Start the SAP instance
#
saphana_start() {

  sapuserexit PRE_START_USEREXIT "$OCF_RESKEY_PRE_START_USEREXIT"

  local rc=$OCF_NOT_RUNNING
  local output=""
  local loopcount=0

  while [ $loopcount -lt 2 ]
  do
    loopcount=$(($loopcount + 1))

    check_sapstartsrv
    rc=$?
    if [ $rc -eq $OCF_SUCCESS ]; then
      output=`$SAPCONTROL -nr $InstanceNr -function Start`
      rc=$?
      ocf_log info "Starting SAP Instance $SID-$InstanceName: $output"
    fi

    if [ $rc -ne 0 ]
    then
      ocf_log err "SAP Instance $SID-$InstanceName start failed."
      return $OCF_ERR_GENERIC
    fi

    local startrc=1
    while [ $startrc -gt 0 ]
    do
      local waittime_start=`date +%s`
      output=`$SAPCONTROL -nr $InstanceNr -function WaitforStarted $OCF_RESKEY_START_WAITTIME 10`
      startrc=$?
      local waittime_stop=`date +%s`

      if [ $startrc -ne 0 ]
      then
        if [ $(($waittime_stop - $waittime_start)) -ge $OCF_RESKEY_START_WAITTIME ]
        then
          saphana_monitor NOLOG
          if [ $? -eq $OCF_SUCCESS ]
          then
            output="START_WAITTIME ($OCF_RESKEY_START_WAITTIME) has elapsed, but instance monitor returned SUCCESS. Instance considered running."
            startrc=0; loopcount=2
          fi
        else
          if [ $loopcount -eq 1 ] && ocf_is_true $OCF_RESKEY_AUTOMATIC_RECOVER
          then
            ocf_log warn "SAP Instance $SID-$InstanceName start failed: $output"
            ocf_log warn "Try to recover $SID-$InstanceName"
            cleanup_instance
          else
            loopcount=2
          fi
          startrc=-1
        fi
      else
        loopcount=2
      fi
    done
  done

  if [ $startrc -eq 0 ]
  then
    ocf_log info "SAP Instance $SID-$InstanceName started: $output"
    rc=$OCF_SUCCESS
    sapuserexit POST_START_USEREXIT "$OCF_RESKEY_POST_START_USEREXIT"
  else
    ocf_log err "SAP Instance $SID-$InstanceName start failed: $output"
    rc=$OCF_NOT_RUNNING
  fi

  return $rc
}


#
# saphana_recover: Try startup of failed instance by cleaning up resources
#
saphana_recover() {
  cleanup_instance
  saphana_start
  return $?
}


#
# saphana_stop: Stop the SAP instance
#
saphana_stop() {
  local output=""
  local rc

  sapuserexit PRE_STOP_USEREXIT "$OCF_RESKEY_PRE_STOP_USEREXIT"

  if [ "$OCF_RESKEY_SHUTDOWN_METHOD" = "KILL" ]
  then
    ocf_log info "Stopping SAP Instance $SID-$InstanceName with shutdown method KILL!"
    cleanup_instance
    return $OCF_SUCCESS
  fi

  check_sapstartsrv
  rc=$?
  if [ $rc -eq $OCF_SUCCESS ]; then
    output=`$SAPCONTROL -nr $InstanceNr -function Stop`
    rc=$?
    ocf_log info "Stopping SAP Instance $SID-$InstanceName: $output"
  fi

  if [ $rc -eq 0 ]
  then
    output=`$SAPCONTROL -nr $InstanceNr -function WaitforStopped 3600 1`
    if [ $? -eq 0 ]
    then
      ocf_log info "SAP Instance $SID-$InstanceName stopped: $output"
      rc=$OCF_SUCCESS
    else
      ocf_log err "SAP Instance $SID-$InstanceName stop failed: $output"
      rc=$OCF_ERR_GENERIC
    fi
  else
    ocf_log err "SAP Instance $SID-$InstanceName stop failed: $output"
    rc=$OCF_ERR_GENERIC
  fi

  sapuserexit POST_STOP_USEREXIT "$OCF_RESKEY_POST_STOP_USEREXIT"

  return $rc
}


#
# saphana_monitor: Can the given SAP instance do anything useful?
#
saphana_monitor() {
  local MONLOG=$1
  local rc

  check_sapstartsrv
  rc=$?

  if [ $rc -eq $OCF_SUCCESS ]
  then
    local count=0
    local SERVNO
    local output

    output=`$SAPCONTROL -nr $InstanceNr -function GetProcessList -format script`

    # we have to parse the output, because the returncode doesn't tell anything about the instance status
    for SERVNO in `echo "$output" | grep '^[0-9] ' | cut -d' ' -f1 | sort -u`
    do
      local COLOR=`echo "$output" | grep "^$SERVNO dispstatus: " | cut -d' ' -f3`
      local SERVICE=`echo "$output" | grep "^$SERVNO name: " | cut -d' ' -f3`
      local STATE=0
      local SEARCH

      case $COLOR in
        GREEN|YELLOW)       STATE=$OCF_SUCCESS;;
        *)                  STATE=$OCF_NOT_RUNNING;;
      esac 

      SEARCH=`echo "$OCF_RESKEY_MONITOR_SERVICES" | sed 's/\+/\\\+/g' | sed 's/\./\\\./g'`
      if [ `echo "$SERVICE" | egrep -c "$SEARCH"` -eq 1 ]
      then
          if [ $STATE -eq $OCF_NOT_RUNNING ]
          then
            [ "$MONLOG" != "NOLOG" ] && ocf_log err "SAP instance service $SERVICE is not running (status $COLOR) !"
            rc=$STATE
          fi
          count=1
      fi
    done

    if [ $count -eq 0 -a $rc -eq $OCF_SUCCESS ]
    then
      if ocf_is_probe
      then
        rc=$OCF_NOT_RUNNING
      else
        [ "$MONLOG" != "NOLOG" ] && ocf_log err "The SAP instance does not run any services which this RA could monitor!"
        rc=$OCF_ERR_GENERIC
      fi
    fi
  fi
 
  return $rc
}


#
# saphana_status: Lightweight check of SAP instance only with OS tools
#
saphana_status() {
  local pid
  local pids

echo "fhDBD: saphana_status: SID=$SID"
echo "fhDBD: saphana_status: InstanceName=$InstanceName"

  [ ! -f "/usr/sap/$SID/$InstanceName/work/kill.sap" ] && return $OCF_NOT_RUNNING
  pids=`grep '^kill -[0-9]' /usr/sap/$SID/$InstanceName/work/kill.sap | awk '{print $3}'`
  for pid in $pids
  do
    [ `pgrep -f -U $sidadm $InstanceName | grep -c $pid` -gt 0 ] && return $OCF_SUCCESS
  done
  return $OCF_NOT_RUNNING
}


#
# saphana_validate: Check the symantic of the input parameters 
#
saphana_validate() {
  local rc=$OCF_SUCCESS
  if [ `echo "$SID" | grep -c '^[A-Z][A-Z0-9][A-Z0-9]$'` -ne 1 ]
  then
    ocf_log err "Parsing instance profile name: '$SID' is not a valid system ID!"
    rc=$OCF_ERR_ARGS
  fi

  if [ `echo "$InstanceName" | grep -c '^[A-Z].*[0-9][0-9]$'` -ne 1 ]
  then
    ocf_log err "Parsing instance profile name: '$InstanceName' is not a valid instance name!"
    rc=$OCF_ERR_ARGS
  fi

  if [ `echo "$InstanceNr" | grep -c '^[0-9][0-9]$'` -ne 1 ]
  then
    ocf_log err "Parsing instance profile name: '$InstanceNr' is not a valid instance number!"
    rc=$OCF_ERR_ARGS
  fi

  if [ `echo "$SAPVIRHOST" | grep -c '^[A-Za-z][A-Za-z0-9_-]*$'` -ne 1 ]
  then
    ocf_log err "Parsing instance profile name: '$SAPVIRHOST' is not a valid hostname!"
    rc=$OCF_ERR_ARGS
  fi

  return $rc
}

# set the hana_sync_status attribute
#   param: STATUS [ HOST-LIST ]
set_hana_sync_status_attr()
{
   local rc theStatus theHosts
   if [ $# -ge 2 ]; then
      theStatus=$1
      shift
      theHosts=$(echo $* | dequote)
      for theHost in $theHosts; do
          ocf_log info "fhDBG Seting node $theHost attribute $ATTR_NAME_HANA_SYNC_STATUS = $theStatus"
          ocf_log info "fhDBG crm_attribute -v "$theStatus" -n "$ATTR_NAME_HANA_SYNC_STATUS" -l reboot -N $theHost"
          crm_attribute -v "$theStatus" -n "$ATTR_NAME_HANA_SYNC_STATUS" -l reboot -N $theHost; crm_rc=$?
	   # TODO: maybe we do need error handling!!
      done
      rc=0
   else
      rc=1
   fi
   return $rc
}

get_hana_sync_status_attr()
{
   local sync_attr
   sync_attr=$(crm_attribute -N ${HOSTNAME} -G -n "$ATTR_NAME_HANA_SYNC_STATUS" -l reboot -q)

   # OLD ATTRIBUTE IN PROPETRY INSTEAD OF HOSTS ATTRIBUTES
   #crm_attribute -G -n "$ATTR_NAME_HANA_SYNC_STATUS" -q
   # TODO: Do we need error handling?
   echo "$sync_attr"
}

#
# set the hana_primary_at attribute
#   param: location like WALLDORF or ROT
#
set_hana_primary_at_attr()
{
   theLocation=$1
   crm_attribute -v "$theLocation" -n "$ATTR_NAME_HANA_PRIMARY_AT"
   # TODO: Do we need error handling?
}

#
# get the hana_primary_at attribute
#
get_hana_primary_at_attr()
{
   crm_attribute -G -n "$ATTR_NAME_HANA_PRIMARY_AT" -q
   # TODO: Do we need error handling?
}

check_for_primary() {

   # node_status=$(su - ${sidadm} -c "hdbnsutil -sr_state" 2>/dev/null | awk '/mode/ {print $2}')
   # TODO: Change stderr location!!
   # TODO: Fix hdbnsutil location
   # TODO: Fix user sidadm
   #sidadm=lnxadm
   node_status=$(check_for_primary_single) 
   ocf_log info "check_for_primary: node_status=$node_status"
   case "$node_status" in
       primary ) 
                  return $HANA_STATE_PRIMARY;;
       syncmem | sync | async )
                  return $HANA_STATE_SECONDARY;;
       none )     # have seen that mode on second side BEFEORE we registered it as replica
                  return $HANA_STATE_DEFECT;;
       * )
		  ocf_log err "check_for_primary:  we didn't expect node_status to be: <$node_status>"
                  ocf_log err "check_for_primary: trying multiple times to get primary status"
                  for i in 1 2 3 4 5; do
                      node_status=$(check_for_primary_single)
                      ocf_log info "check_for_primary: (loop nr $i) node_status=$node_status"
                      case "$node_status" in
                           primary )
                                     return $HANA_STATE_PRIMARY;;
                           syncmem* | sync* | async* )
                                     # TODO: instead of wildcards we should be sharper, but need to check for possible strings 
                                     return $HANA_STATE_SECONDARY;;
                      esac
                      sleep 10
                  done
		  # sync and async seen in the hdbnsutil help -- need to know how to handle them
                  return $HANA_STATE_DEFECT;;
   esac;
   return $HANA_STATE_DEFECT
}

#
# saphana_start_clone
#
saphana_start_clone() {
	local primary_status sync_attr score_master rc=$OCF_NOT_RUNNING
	ocf_log info "fhDBG set attribute $ATTR_NAME_HANA_CLONE_STATE for node $(hostname) to DEMOTED"
	crm_attribute -N $(hostname) -v DEMOTED  -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot
	check_for_primary; primary_status=$?
	if [ $primary_status -eq $HANA_STATE_PRIMARY ]; then
		#
		# we will be a master (primary) so checking, if the is an other master
		#
# TODO: Do we need to check, if a primary is already rechable (sql) - normaly a dual master may not happen (master_max=1)
#       But as HANA may come up with primary configurattion also at slave side we need to check that
#       Also - what to do on a side, where primary config is available but there is already a primary - should we than
#       register that side as secondary?
##		if [ -n "$Master_Nodes" ]; then
#			if [ "$Master_Nodes" != "$(hostname)" ]; then
#				ocf_log warn "!!!!!!!!!!! Master_Nodes=\"$Master_Nodes\" !!!!!!!!!!!!!"
#				ocf_log err  "!!!!!!!!!!! SAPHana MUST never be primary-primary !!!!!!!!!!!!!"
#				#
#				# DO NOT PROMOTE HERE
#				# TODO: Could we repair that situation?
#				#
#				ocf_log info "fhDES: primary-primary detected - block this clone!"
#				set_crm_master -INFINITY
#				return $OCF_ERR_GENERIC
#			fi
#		else
			score_master=$(get_crm_master)
			if [ "$score_master" = "-INFINITY" -o "$score_master" -lt 0 ]; then
				ocf_log info "fhDES: primary and only primary BUT have penality - so we should NOT promote here"
				set_crm_master  0
			else
				# we are primary and we are alone - so we could promote
				ocf_log info "fhDES: primary and only primary, we have no penality - so we could promote here"
				set_crm_master  100
			fi
#		fi
		saphana_start
		rc=$?
	else 
		#
		# we would be slave (secondary)
		# we first need to check, if there are Master Nodes, because the Scecondary only starts
		# successfuly, if the Primary is available. Thatfore we mark the Secondary as "WAITING"
#
# TODO: Parameter for hardcoded IP address
#       to get this IP address/virt-hostname - we could either rechange the use od the InstanceName OR defining an own parameter like VirtName
#
                        remote_sql=10.17.140.200
# WORKING-ZONE
# TODO: we should get rid of user system and pwd manager and using a secure store db user
#
                        $DIR_EXECUTABLE/hdbsql -a -x -u system -p manager -n $remote_sql -i 42 'select distinct REPLICATION_STATUS from SYS.M_SERVICE_REPLICATION' 2>/dev/null 1>/dev/null; sqlrc=$?
		if [ $sqlrc -ne 0 ]; then
			ocf_log info "fhDBG set attribute $ATTR_NAME_HANA_CLONE_STATE for node $(hostname) to WAITING"
			crm_attribute -N $(hostname) -v WAITING  -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot
			ocf_log info "fhDES: secondary in status WAITING -> EXCLUDE as posible takeover node"
			set_crm_master -INFINITY
			rc=$OCF_SUCCSESS
		else
			saphana_start; rc=$?
			sync_attr=$(get_hana_sync_status_attr)
			case "$sync_attr" in
				"OK"   )    # This is a possible node to promote, when primary is missing
							ocf_log info "fhDES: secondary with sync status OK -> posible takeover node"
							set_crm_master  10
							;;
				"FAILURE" ) # This is currently NOT a possible node to promote
							ocf_log info "fhDES: secondary with sync status FAILED -> EXCLUDE as posible takeover node"
							set_crm_master -INFINITY
							;;
				"*" )       # Unknown sync status
							ocf_log info "fhDES: secondary with sync status UKNOWN/UNDEFINED -> EXCLUDE as posible takeover node"
							set_crm_master -INFINITY
							;;
			esac
		fi
	fi 
	return $rc
}


#
# saphana_stop_clone
#
saphana_stop_clone() {
    # TODO: fh - when to check, if this is/was master already?
    ocf_log info "fhDBG set attribute $ATTR_NAME_HANA_CLONE_STATE for node $(hostname) to UNDEFINED"
    crm_attribute -N $(hostname) -v UNDEFINED  -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot
    saphana_stop
    return $?
}


check_for_primary_single()
{
    local node_full_status node_status
    echo " ========== $(date) ============== " >>/tmp/null
    #
    # TODO: remove debug-output to /tmp/null
    #
    # ocf_log info "fhDBG sidadm=${sidadm}, SID=${SID}, LD_LIBRARY_PATH=${LD_LIBRARY_PATH}, PATH=${PATH}, DIR_EXECUTABLE=$DIR_EXECUTABLE"
    node_full_status=$(su - ${sidadm} -c "LD_LIBRARY_PATH=$LD_LIBRARY_PATH $DIR_EXECUTABLE/hdbnsutil -sr_state" 2>>/tmp/null )
    echo "${node_full_status}" >>/tmp/null
    node_status=$(echo "$node_full_status" | awk '$1=="mode:" {print $2}')
    echo "$node_status"
}

#
# get site name of local HANA instance
#
get_site_name()
{
    local node_full_status node_site_name
    #
    # TODO: check how to remove the paths
    #
    #ocf_log info "fhDBG sidadm=${sidadm}, SID=${SID}, LD_LIBRARY_PATH=${LD_LIBRARY_PATH}, PATH=${PATH}, DIR_EXECUTABLE=$DIR_EXECUTABLE"
    node_full_status=$(su - ${sidadm} -c "LD_LIBRARY_PATH=$LD_LIBRARY_PATH $DIR_EXECUTABLE/hdbnsutil -sr_state" 2>>/tmp/null )
    echo "${node_full_status}" >>/tmp/null
    node_site_name=$(echo "$node_full_status" | awk '/^site name:/ { printf "<%s>/n", $3 } ' )
    echo "$node_site_name"
}

#
# get the HANA sync status
# 
analyze_hana_sync_status()
{
    local hana_sync_status what_does_the_camaelion_say
    #
    hana_sync_status=$($DIR_EXECUTABLE/hdbsql -a -x -u system -p manager -n localhost -i 42 'select distinct REPLICATION_STATUS from SYS.M_SERVICE_REPLICATION' | dequote)
    #
    # UNKNOWN, ACTIVE, ERROR, INITIALIZING
    #
    if [ "${hana_sync_status}" == "ACTIVE" ]; then
        ocf_log info set_hana_sync_status_attr "OK"
        set_hana_sync_status_attr "OK"
    else
        ocf_log warn "HANA SYNC STATUS is: ${hana_sync_status}"
        ocf_log info set_hana_sync_status_attr "FAILURE"
        set_hana_sync_status_attr "FAILURE"
    fi

    # first get a list of all secondary hosts, than a list of all secondary hosts, if the is ANY failure at this site
    #    TODO: for first we assume there is only ONE secondary site
    #    TODO: error handling of hdbsql
    #    TODO: Use secure-store user instead of username/passwd --> this prereq must be checked! 
    #
    all_secondary_hosts=$(hdbsql -a -x -u system -p manager -n localhost -i 42 "(select distinct  SECONDARY_HOST from SYS.M_SERVICE_REPLICATION)")
    all_broken_secondary_hosts=$(hdbsql -a -x -u system -p manager -n localhost -i 42 "select distinct SECONDARY_HOST from SYS.M_SERVICE_REPLICATION  where SECONDARY_SITE_NAME = (select distinct  SECONDARY_SITE_NAME from SYS.M_SERVICE_REPLICATION WHERE REPLICATION_STATUS != 'ACTIVE')" | dequote)
    if [ -n "$all_broken_secondary_hosts" ]; then
        #
        # we have a broken secondary site - set all hosts to "FAILURE"
        #
        what_does_the_camaelion_say=$(set_hana_sync_status_attr "FAILURE" $all_broken_secondary_hosts 2>&1)
    else 
        #
        # we have an ACTIVE secondary site - set all hosts to "OK"
        #
        what_does_the_camaelion_say=$(set_hana_sync_status_attr "OK" $all_secondary_hosts 2>&1)
    fi
}

#
# get the HANA landscape status
#
get_hana_landscape_status()
{
    local ls_rc=0
    #
    su - $sidadm -c "python $DIR_EXECUTABLE/python_support/landscapeHostConfiguration.py" 1>/dev/null 2>/dev/null; ls_rc=$?
    # ls_rc:
    # 0 : FATAL
    # 1 : ERROR
    # 2 : WARN
    # 3 : INFO
    # 4 : OK
    return $ls_rc;
}

#
# register_hana_secondary
#
register_hana_secondary()
{
    local rc=2;
    # TODO: implementation :)
    # HANA nedds to be stopped to register!
    # as sidadm
    # hdbnsutil -sr_register --remoteHost=lv9041 --remoteInstance=42 --mode=syncmem --name=ROT
    # --remoteHost=  this is the (new) primary host
    # --remoteInstance= this is the (new) primaries instance number - do we assume the same number?
    # --name= this is the local(!) site name 
    return rc;
}

#
# saphana_monitor_clone
#
saphana_monitor_clone() {
#
# TODO: For the secondary, which is missing the primary (so in status WAITING) what is better:
#       a) returning 7 here and force cluster a restart of the slave
#       b) starting the instance here inside the monitor -> may result in longer runtime, timeouts
#
	# first check with the status function (OS tools) if there could be something like a SAP instance running
	# as we do not know here, if we are in master or slave state we do not want to start our monitoring
	# agents (sapstartsrv) on the wrong host
	local rc=$OCF_ERR_GENERIC
	local promoted=0
    local init_attribute=0

	if ocf_is_probe; then
		ocf_log info "fhDBG: PROBE ONLY"
	else
		ocf_log info "fhDBG: REGULAR MONITOR"
	fi
	#
	# First check, if we are PRIMARY or SECONDARY
	# 
	check_for_primary; primary_status=$?
    if [ $primary_status -eq $HANA_STATE_PRIMARY ]; then
        #
        # OK, we are running as HANA PRIMARY
        #
        ocf_log info "fhDBG saphana_monitor_clone: HANA_STATE_PRIMARY"
        #
        ##### CHECK, IF WE ARE DEMOTED (CLUSTER NODE ATTRIBUTE)
        #
        promote_attr=$(crm_attribute -N ${HOSTNAME} -G -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot -q)
        ocf_log info "fhDBG saphana_monitor_clone: $ATTR_NAME_HANA_CLONE_STATE=$promote_attr"
        if [ -z "$promote_attr" ]; then
            init_attribute=1
            promoted=0;
        else
            case "$promote_attr" in
                PROMOTED )
                    promoted=1;
                    ;;
                DEMOTED )
                    promoted=0;
                    ;;
                WAITING )  # However - WAITING should never happeb for a PRIMARY
                    promoted=0;
                    ;;
                * )
                    promoted=0;
                    ;;
            esac
        fi
        #
        ##### old method was: saphana_monitor - new method is get_hana_landscape_status
        #
        get_hana_landscape_status; lss=$? 
        ocf_log info "fhDBG saphana_monitor_clone: get_hana_landscape_status=$lss"
        case "$lss" in
            0 | 1 ) # FATAL or ERROR
                if ocf_is_probe; then
                    # 
                    # leave master score untouched, only set return code
                    #
                    rc=$OCF_NOT_RUNNING
                else
                    if [ "$promoted" -eq 1 ]; then
                        # INSTANCE IS FAILED PRIMARY IN PROMOTED STATE
                        # TODO: Adjust with set_crm_master?
                        #       For Migration it would be good to decrease master score
                        #       For Reload locally we should NOT adjust the master score
                        # ===>  Should we rely on the migration threshold?
                        #       set_crm_master 
                        if [ $PreferSiteTakeover -eq 1 ]; then
                            ocf_log info "fhDES: PreferSiteTakeover selected so decrease promotion score here"
                            set_crm_master -9000
                        fi
                        rc=$OCF_FAILED_MASTER
                    else
                        # INSTANCE IS FAILED PRIMARY IN DEMOTED STATE
                        # TODO: Adjust with set_crm_master?
                        #       Current decission: Do NOT adjust master score now as other
                        #       steps ahould already have done that
                        #
                        rc=$OCF_NOT_RUNNING
                    fi
                fi
                ;;
            2 | 3 | 4 ) # WARN INFO OK
                if ocf_is_probe; then
                    rc=$OCF_SUCCESS
                else
                    if [ "$promoted" -eq 1 ]; then
                        rc=$OCF_RUNNING_MASTER
                    else
                        if [ "$init_attribute" -eq 1 ]; then
                            ocf_log info "fhDBG set attribute $ATTR_NAME_HANA_CLONE_STATE for node $(hostname) to PROMOTED"
                            crm_attribute -N $(hostname) -v PROMOTED -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot
                            rc=$OCF_RUNNING_MASTER
                        else
                            rc=$OCF_SUCCESS
                        fi
                    fi
                    analyze_hana_sync_status
                fi
                ;;
            * ) # UNDEFINED STATUS
                if ocf_is_probe; then
                    rc=$OCF_NOT_RUNNING
                else
                    if [ "$promoted" -eq 1 ]; then
                         rc=$OCF_FAILED_MASTER
                    else
                         rc=$OCF_NOT_RUNNING
                    fi
                fi
                ;;
        esac 
    else
        if [ $primary_status -eq $HANA_STATE_SECONDARY  ]; then
            #
            # OK, we are running as HANA SECONDARY (or even not as PRIMARY)
            # TODO: WE NEED TO HANDLE NEW WAITING STATUS
            #
            ##### CHECK, IF WE ARE DEMOTED (CLUSTER NODE ATTRIBUTE)
            #
            promote_attr=$(crm_attribute -N ${HOSTNAME} -G -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot -q)
            ocf_log info "fhDBG saphana_monitor_clone: $ATTR_NAME_HANA_CLONE_STATE=$promote_attr"
            if [ -z "$promote_attr" ]; then
                init_attribute=1
                #  TODO: do we need to inizialize also the DEMOTED attribute value?
                promoted=0;
            else
                case "$promote_attr" in
                    PROMOTED ) # However - WAITING should never happen for a SECONDARY
                        promoted=1;
                        ;;
                    DEMOTED )  # This is the status we expect
                        promoted=0;
                        ;;
                    WAITING )  # We are WAITING for PRIMARY so not testing the HANA engine now but check for a new start
#
# TODO: We MUST NOT check Master Nodes here - its only valid in notify action
#
#                        Master_Nodes=$(echo $meta_notify_master_uname | dequote )
#                        if [ -n "$Master_Nodes" ]; then
#                            ocf_log info "fhDBG saphana_monitor_clone: SECONDARY still in status WAITING - Primary available - try a new start"
#                            saphana_start_clone
#                            rc=$?
#                        else
#                            ocf_log info "fhDBG saphana_monitor_clone: SECONDARY still in status WAITING - Primary missing"
#                            return $OCF_SUCCESS
#                        fi
# TODO: Parameter for hardcoded IP address
                        remote_sql=10.17.140.200
# WORKING-ZONE
                        $DIR_EXECUTABLE/hdbsql -a -x -u system -p manager -n $remote_sql -i 42 'select distinct REPLICATION_STATUS from SYS.M_SERVICE_REPLICATION' 2>/dev/null 1>/dev/null; sqlrc=$?
                        if [ $sqlrc -eq 0 ]; then
                            ocf_log info "fhDBG saphana_monitor_clone: SECONDARY still in status WAITING - Primary now available - try a new start"
                            saphana_start_clone
                            rc=$?
                        else
                            ocf_log info "fhDBG saphana_monitor_clone: SECONDARY still in status WAITING - Primary is still missing (sqlrc=$sqlrc)"
                            return $OCF_SUCCESS
                        fi
                        
                        promoted=0;
                        ;;
                    PREPARE ) # Notify action has noticed an available primary - try a new start
                        ocf_log info "fhDBG saphana_monitor_clone: SECONDARY still in status WAITING - Primary available - try a new start"
                        saphana_start_clone
                        rc=$?
                        promoted=0;
                        ;;
                    * )
                        promoted=0;
                        ;;
                esac
            fi
            #
            ocf_log info "fhDBG saphana_monitor_clone: HANA_STATE_SECONDARY"
            #
            # old method was: saphana_monitor - new method is get_hana_landscape_status
            get_hana_landscape_status; lss=$? 
            ocf_log info "fhDBG saphana_monitor_clone: get_hana_landscape_status=$lss"
            case "$lss" in
                0 | 1 ) # FATAL or ERROR
                    rc=$OCF_NOT_RUNNING
                    ;;
                2 | 3 | 4 ) # WARN INFO OK
                    rc=$OCF_SUCCESS
                    sync_attr=$(get_hana_sync_status_attr)
                    ocf_log info "fhDBG sync_attr=$sync_attr"
                    case "$sync_attr" in
                        "OK"   )    # This is a possible node to promote, when primary is missing
                            ocf_log info "fhDES: secondary with sync status OK -> posible takeover node"
                            set_crm_master  10
                            ;;
                        "FAILURE" ) # This is currently NOT a possible node to promote
                            ocf_log info "fhDES: secondary with sync status FAILED -> EXCLUDE as posible takeover node"
                            set_crm_master -INFINITY
                            ;;
                        "*" )       # Unknown sync status
                            ocf_log info "fhDES: secondary with sync status UKNOWN/UNDEFINED -> EXCLUDE as posible takeover node"
                            set_crm_master -INFINITY
                            ;;
                    esac
                    ;;
                * ) # UNDEFINED STATUS
                    rc=$OCF_NOT_RUNNING
                    ;;
            esac 
        else
            #
            # OK, we are neither HANA PRIMARY nor HANA SECONDARY
            #
            ocf_log info "fhDBG saphana_monitor_clone: HANA_STATE_DEFECT"
            # TODO: Or only set_crm_master -INFINITY ?
            rc=$OCF_ERR_GENERIC
        fi
    fi
    return $rc
}


#
# saphana_promote_clone: In a Master/Slave configuration get Master being the primary OR by running hana takeover
#
saphana_promote_clone() {
  local rc
  rc=$OCF_ERR_GENERIC;
  #
  # first check, if we WILL be PRIMARY (checking HANA status)
  #
  check_for_primary; primary_status=$?
  #
  if [ $primary_status -eq $HANA_STATE_PRIMARY ]; then
     #
     # as we are already planned to be master we only mark the node as primary
     #
     ocf_log info "fhDBG set attribute $ATTR_NAME_HANA_CLONE_STATE for node $(hostname) to PROMOTED"
     crm_attribute -N $(hostname) -v PROMOTED -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot
     rc=$OCF_SUCCESS;
     ocf_log info "Promoted $SID-$InstanceName as master (no hdbnsutil action needed)."
  else
     if [ $primary_status -eq $HANA_STATE_SECONDARY ]; then
        #
        # we are SLAVE and need to takepover ...
        # promote on the replica side...
        #
        hana_sync=$(get_hana_sync_status_attr)
        case "$hana_sync" in
             OK )
		ocf_log info "!!!!!!! Promote REPLICA $SID-$InstanceName to be primary. !!!!!!"
		#####
		su - $sidadm -c "hdbnsutil -sr_takeover"
		# TODO: do we need to check return codes, or does the check_for_primary test works successful?
		#
		# now gain check, if we are primary NOW
		#
		# TODO: check, if we need to destigush between HANA_STATE_PRIMARY, HANA_STATE_SECONDARY, HANA_STATE_DEFECT
		#
		if check_for_primary; then
                   ocf_log info "fhDBG set attribute $ATTR_NAME_HANA_CLONE_STATE for node $(hostname) to PROMOTED"
                   crm_attribute -N $(hostname) -v PROMOTED -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot
		   rc=$OCF_SUCCESS;
		else
                   ocf_log info "fhDBG set attribute $ATTR_NAME_HANA_CLONE_STATE for node $(hostname) to PROMOTED"
                   crm_attribute -N $(hostname) -v PROMOTED -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot
		   rc=$OCF_ERR_GENERIC
		fi 
                ;;
             * )
                ocf_log err "!!!!!!! HANA SYNC STATUS IS NOT 'OK' SO WE COULD NOT PROMOTE !!!!!!!"
                rc=$OCF_ERR_GENERIC
                ;;
        esac
     else
        #
        # neither MASTER nor SLAVE - This clone instance seams broken!!
        #
        rc=$OCF_ERR_GENERIC
     fi
  fi
  rc=$?
  return $rc
}


#
# saphana_demote_clone: In a Master/Slave configuration get Slave by stopping the SCS instance and starting the ERS instance
#
saphana_demote_clone() {
    local rc
    rc=$OCF_ERR_GENERIC;
    #
    # TODO: currently not implemented - how to DEMOTE a HANA PRIMARY?
    # 
    ocf_log info "fhDBG set attribute $ATTR_NAME_HANA_CLONE_STATE for node $(hostname) to DEMOTED"
    crm_attribute -N $(hostname) -v DEMOTED  -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot
    rc=$OCF_SUCCESS;
    ocf_log info "Demoted $SID-$InstanceName as slave."
    # saphana_stop
    return $rc
}

saphana_notify_log_values()
{
    # params: name value
    local name=$1
    local value=$2
    local separator="/"
    
    if [ -n "$value" ]; then
       if [ "$(echo $value | tr -d ' ')" != "$separator" ]; then
		ocf_log info "saphana_notify: $name $value"
          
       fi 
    fi
} 


#
# saphana_notify: Handle master scoring - to make sure a slave gets the next master
#
saphana_notify() {
    local promote_attr
    #
    # related to notification
    #

    local n_type="$OCF_RESKEY_CRM_meta_notify_type"
    local n_op="$OCF_RESKEY_CRM_meta_notify_operation"
    ocf_log info "==== begin action $ACTION$CLACT (${n_type}/${n_op})===="

    #
    # related to resources
    #

    local n_act="$OCF_RESKEY_CRM_meta_notify_active_resource"
    local n_iact="$OCF_RESKEY_CRM_meta_notify_inactive_resource"
    saphana_notify_log_values "n_act/n_iact" "${n_act}/${n_iact}"

    local n_master="$OCF_RESKEY_CRM_meta_notify_master_resource"
    local n_slave="$OCF_RESKEY_CRM_meta_notify_slave_resource"
    saphana_notify_log_values "n_master/n_slave" "${n_master}/${n_slave}"

    local n_start="$OCF_RESKEY_CRM_meta_notify_start_resource"
    local n_stop="$OCF_RESKEY_CRM_meta_notify_stop_resource"
    saphana_notify_log_values "n_start/n_stop" "${n_start}/${n_stop}"

    local n_promote="$OCF_RESKEY_CRM_meta_notify_promote_resource"
    local n_demote="$OCF_RESKEY_CRM_meta_notify_demote_resource"
    saphana_notify_log_values "n_promote/n_demote" "${n_promote}/${n_demote}"

    #
    # related to nodes
    #

    local n_startU="$OCF_RESKEY_CRM_meta_notify_start_uname"
    local n_stopU="$OCF_RESKEY_CRM_meta_notify_stop_uname"
    saphana_notify_log_values "n_startU/n_stopU" "${n_startU}/${n_stopU}"

    local n_promoteU="$OCF_RESKEY_CRM_meta_notify_promote_uname"
    local n_demoteU="$OCF_RESKEY_CRM_meta_notify_demote_uname"
    saphana_notify_log_values "n_promoteU/n_demoteU" "${n_promoteU}/${n_demoteU}"

    local n_actU="$OCF_RESKEY_CRM_meta_notify_active_uname"
    local n_iactU="$OCF_RESKEY_CRM_meta_notify_inactive_uname"
    saphana_notify_log_values "n_actU/n_iactU" "${n_actU}/${n_iactU}"

    local n_masterU="$OCF_RESKEY_CRM_meta_notify_master_uname"
    local n_slaveU="$OCF_RESKEY_CRM_meta_notify_slave_uname"
    saphana_notify_log_values "n_masterU/n_slaveU" "${n_masterU}/${n_slaveU}"


    case "${n_type}_${n_op}" in
	post_start )
# WORKING-ZONE
                     promote_attr=$(crm_attribute -N ${HOSTNAME} -G -n "$ATTR_NAME_HANA_CLONE_STATE" -l reboot -q)
		     case "$promote_attr" in
                         WAITING )  
                                    
                                    ;;
                     esac
                     ;;
    esac

    # TODO: Check when we need to change master/promotion scores
    #if false; then
    #    if [ "${n_type}_${n_op}" = "post_promote" ]; then
    #        # After promotion of one master in the cluster, we make sure that all clones reset their master
    #        # value back to 100. This is because a failed monitor on a master might have degree one clone
    #        # instance to score 10.
    #        # TODO: a) check, if the "story" is still correct for SAPHana in scale-up and scale-out
    #        #       b) are the values 10 / 100 still correct?
    #        set_crm_master 100
    #    elif [ "${n_type}_${n_op}" = "pre_demote" ]; then
    #        # if we are a slave and a demote event is anounced, make sure we have the highes wish to became master
    #        # that is, when a slave resource was startet after the promote event of a already running master (e.g. node of slave was down)
    #        # We also have to make sure to overrule the globaly set resource_stickiness or any fail-count factors => INFINITY
    #        local n_uname="$OCF_RESKEY_CRM_meta_notify_demote_uname"
    #        if [ ${n_uname} != ${HOSTNAME} ]; then
    #            set_crm_master INFINITY
    #        fi
    #    fi
    #fi
    ocf_log info "==== end action $ACTION$CLACT (${n_type}/${n_op})===="
}


#
#	'main' starts here...
#

## GLOBALS
SID=""
sidadm=""
InstanceName=""
InstanceNr=""
SAPVIRHOST=""
DIR_EXECUTABLE=""
SAPSTARTSRV=""
SAPCONTROL=""
DIR_PROFILE=""
SAPSTARTPROFILE=""


if [ $# -ne 1 ]
then
  saphana_usage
  exit $OCF_ERR_ARGS
fi

ACTION=$1
if [ "$ACTION" = "status" ]; then
    ACTION=monitor
fi

# These operations don't require OCF parameters to be set
# TODO: check, if notify is still not needing OCF parameters
case "$ACTION" in
    usage|methods)                saphana_$ACTION
                                exit $OCF_SUCCESS;;
    meta-data)                    saphana_meta_data
                                exit $OCF_SUCCESS;;
    notify)                       
                                saphana_notify
                                exit $OCF_SUCCESS;;
    *);;
esac
saphana_init $OCF_RESKEY_InstanceName

if ! ocf_is_root
then
    ocf_log err "$0 must be run as root"
    exit $OCF_ERR_PERM
fi

# parameter check
if  [ -z "$OCF_RESKEY_InstanceName" ]
then
    ocf_log err "Please set OCF_RESKEY_InstanceName to the name to the SAP instance profile!"
    exit $OCF_ERR_ARGS
fi

if is_clone
then
    CLACT=_clone
else
    if [ "$ACTION" = "promote" -o "$ACTION" = "demote" ]
    then
        ocf_log err "$ACTION called in a non master/slave environment"
        exit $OCF_ERR_ARGS
    fi
fi

# What kind of method was invoked?
ocf_log info "==== begin action $ACTION$CLACT ===="
ra_rc=$OCF_ERR_UNIMPLEMENTED
case "$ACTION" in
    start|stop|monitor|promote|demote) # Standard controling actions
        saphana_$ACTION$CLACT
        ra_rc=$?
        ;;
    validate-all) # TODO: need to add coding here
        saphana_validate
        ra_rc=$?
        ;;
    *)  # seams to be a unknown request 
        saphana_methods 
        ra_rc=$OCF_ERR_UNIMPLEMENTED
        ;;
esac
ocf_log info "==== end action $ACTION$CLACT with rc=${ra_rc} ===="
exit ${ra_rc}
